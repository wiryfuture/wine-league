From 7ccbe0e62fed7f593e38088499d9a973c156902e Mon Sep 17 00:00:00 2001
From: Philip Wilk <wiryfuture@gmail.com>
Date: Tue, 21 Dec 2021 00:18:08 +0000
Subject: [PATCH] LFT-7.0

---
 dlls/kernel32/heap.c           |   69 +-
 dlls/kernel32/tests/heap.c     |   85 +++
 dlls/kernelbase/memory.c       |    7 +-
 dlls/msvcrt/heap.c             |    4 +
 dlls/ntdll/Makefile.in         |    1 +
 dlls/ntdll/heap.c              |  344 ++++++----
 dlls/ntdll/heap_lfh.c          | 1140 ++++++++++++++++++++++++++++++++
 dlls/ntdll/loader.c            |    3 +
 dlls/ntdll/ntdll_misc.h        |   25 +
 dlls/ntdll/string.c            |  244 +++++--
 dlls/ntdll/thread.c            |    1 +
 dlls/ntdll/unix/unix_private.h |    1 +
 include/winnt.h                |    3 +-
 13 files changed, 1701 insertions(+), 226 deletions(-)
 create mode 100644 dlls/ntdll/heap_lfh.c

diff --git a/dlls/kernel32/heap.c b/dlls/kernel32/heap.c
index 02f4587d43b..8c754f66d30 100644
--- a/dlls/kernel32/heap.c
+++ b/dlls/kernel32/heap.c
@@ -325,40 +325,49 @@ SIZE_T WINAPI GlobalSize(HGLOBAL hmem)
        SetLastError(ERROR_INVALID_HANDLE);
        return 0;
    }
-
-   if(ISPOINTER(hmem))
+   __TRY
    {
-      retval=HeapSize(GetProcessHeap(), 0, hmem);
-
-      if (retval == ~(SIZE_T)0) /* It might be a GMEM_MOVEABLE data pointer */
-      {
-          retval = HeapSize(GetProcessHeap(), 0, (char*)hmem - HGLOBAL_STORAGE);
-          if (retval != ~(SIZE_T)0) retval -= HGLOBAL_STORAGE;
-      }
+        if(ISPOINTER(hmem))
+        {
+            retval=HeapSize(GetProcessHeap(), 0, hmem);
+
+            if (retval == ~(SIZE_T)0) /* It might be a GMEM_MOVEABLE data pointer */
+            {
+                retval = HeapSize(GetProcessHeap(), 0, (char*)hmem - HGLOBAL_STORAGE);
+                if (retval != ~(SIZE_T)0) retval -= HGLOBAL_STORAGE;
+            }
+        }
+        else
+        {
+            RtlLockHeap(GetProcessHeap());
+            pintern=HANDLE_TO_INTERN(hmem);
+
+            if(pintern->Magic==MAGIC_GLOBAL_USED)
+            {
+                if (!pintern->Pointer) /* handle case of GlobalAlloc( ??,0) */
+                    retval = 0;
+                else
+                {
+                    retval = HeapSize(GetProcessHeap(), 0, (char *)pintern->Pointer - HGLOBAL_STORAGE );
+                    if (retval != ~(SIZE_T)0) retval -= HGLOBAL_STORAGE;
+                }
+            }
+            else
+            {
+                WARN("invalid handle %p (Magic: 0x%04x)\n", hmem, pintern->Magic);
+                SetLastError(ERROR_INVALID_HANDLE);
+                retval=0;
+            }
+            RtlUnlockHeap(GetProcessHeap());
+        }
    }
-   else
+   __EXCEPT_PAGE_FAULT
    {
-      RtlLockHeap(GetProcessHeap());
-      pintern=HANDLE_TO_INTERN(hmem);
-
-      if(pintern->Magic==MAGIC_GLOBAL_USED)
-      {
-         if (!pintern->Pointer) /* handle case of GlobalAlloc( ??,0) */
-             retval = 0;
-         else
-         {
-             retval = HeapSize(GetProcessHeap(), 0, (char *)pintern->Pointer - HGLOBAL_STORAGE );
-             if (retval != ~(SIZE_T)0) retval -= HGLOBAL_STORAGE;
-         }
-      }
-      else
-      {
-         WARN("invalid handle %p (Magic: 0x%04x)\n", hmem, pintern->Magic);
-         SetLastError(ERROR_INVALID_HANDLE);
-         retval=0;
-      }
-      RtlUnlockHeap(GetProcessHeap());
+       SetLastError( ERROR_INVALID_HANDLE );
+      retval = 0;
    }
+   __ENDTRY
+
    if (retval == ~(SIZE_T)0) retval = 0;
    return retval;
 }
diff --git a/dlls/kernel32/tests/heap.c b/dlls/kernel32/tests/heap.c
index 8558bd7f1b3..660cc430023 100644
--- a/dlls/kernel32/tests/heap.c
+++ b/dlls/kernel32/tests/heap.c
@@ -42,6 +42,7 @@
 static LPVOID (WINAPI *pHeapAlloc)(HANDLE,DWORD,SIZE_T);
 static LPVOID (WINAPI *pHeapReAlloc)(HANDLE,DWORD,LPVOID,SIZE_T);
 static BOOL (WINAPI *pHeapQueryInformation)(HANDLE, HEAP_INFORMATION_CLASS, PVOID, SIZE_T, PSIZE_T);
+static BOOL (WINAPI *pHeapSetInformation)(HANDLE, HEAP_INFORMATION_CLASS, PVOID, SIZE_T);
 static BOOL (WINAPI *pGetPhysicallyInstalledSystemMemory)(ULONGLONG *);
 static ULONG (WINAPI *pRtlGetNtGlobalFlags)(void);
 
@@ -528,6 +529,8 @@ static void test_HeapCreate(void)
     UINT i;
     BOOL error;
     DWORD dwSize;
+    ULONG hci;
+    SIZE_T size;
 
     /* Retrieve the page size for this system */
     GetSystemInfo(&sysInfo);
@@ -624,6 +627,88 @@ static void test_HeapCreate(void)
 
    /* Check that HeapDestroy works */
    ok(HeapDestroy(heap),"HeapDestroy failed\n");
+
+   if (!(pHeapQueryInformation = (void *)GetProcAddress(GetModuleHandleA("kernel32.dll"), "HeapQueryInformation")) ||
+        !(pHeapSetInformation = (void *)GetProcAddress(GetModuleHandleA("kernel32.dll"), "HeapSetInformation")))
+        win_skip("HeapQueryInformation / HeapSetInformation not available\n");
+    else
+    {
+        heap = HeapCreate(0, 0, 0);
+        ok(!!heap, "HeapCreate failed\n");
+
+        mem1 = HeapAlloc(heap, 0, 16);
+        mem2 = HeapAlloc(heap, 0, 16);
+
+        ok(pHeapQueryInformation(heap, HeapCompatibilityInformation, &hci, sizeof(hci), &size),
+           "HeapQueryInformation failed\n");
+        trace("HeapQueryInformation returned %d\n", hci);
+        hci = 0;
+        ok(pHeapSetInformation(NULL, HeapEnableTerminationOnCorruption, NULL, 0),
+           "HeapSetInformation(HeapEnableTerminationOnCorruption) failed\n");
+        ok(pHeapSetInformation((HANDLE)0xdeadbeef, HeapEnableTerminationOnCorruption, &hci, sizeof(hci)),
+           "HeapSetInformation(HeapEnableTerminationOnCorruption) succeeded\n");
+        ok(pHeapSetInformation(heap, HeapEnableTerminationOnCorruption, &hci, sizeof(hci)),
+           "HeapSetInformation(HeapEnableTerminationOnCorruption) succeeded\n");
+        ok(pHeapSetInformation(heap, HeapEnableTerminationOnCorruption, NULL, 0),
+           "HeapSetInformation(HeapEnableTerminationOnCorruption) failed\n");
+        ok(!pHeapQueryInformation(heap, HeapEnableTerminationOnCorruption, NULL, 0, &size),
+           "HeapQueryInformation(HeapEnableTerminationOnCorruption) succeeded\n");
+
+        hci = 2;
+        SetLastError(0xdeadbeef);
+        ok(!pHeapSetInformation(NULL, HeapCompatibilityInformation, NULL, 0),
+           "HeapSetInformation succeeded\n");
+        ok(GetLastError() == ERROR_INSUFFICIENT_BUFFER,
+           "expected ERROR_INSUFFICIENT_BUFFER, got %u\n", GetLastError());
+        ok(!pHeapSetInformation(NULL, HeapCompatibilityInformation, &hci, 2),
+           "HeapSetInformation succeeded\n");
+        ok(GetLastError() == ERROR_INSUFFICIENT_BUFFER,
+           "expected ERROR_INSUFFICIENT_BUFFER, got %u\n", GetLastError());
+        ok(pHeapSetInformation(heap, HeapCompatibilityInformation, &hci, sizeof(hci)),
+           "HeapSetInformation failed\n");
+        ok(pHeapQueryInformation(heap, HeapCompatibilityInformation, &hci, sizeof(hci), &size),
+           "HeapQueryInformation failed\n");
+        trace("HeapQueryInformation returned %d\n", hci);
+
+        hci = 1;
+        SetLastError(0xdeadbeef);
+        ok(!pHeapSetInformation(heap, HeapCompatibilityInformation, &hci, sizeof(hci)),
+           "HeapSetInformation succeeded\n");
+        ok(GetLastError() == ERROR_GEN_FAILURE,
+           "expected ERROR_GEN_FAILURE, got %u\n", GetLastError());
+
+        mem3 = HeapAlloc(heap, 0, 16);
+
+        ok(HeapValidate(heap, 0, NULL), "HeapValidate failed\n");
+
+        SetLastError(0xdeadbeef);
+        dwSize = HeapSize(heap, 0, mem1);
+        ok(dwSize == 16, "HeapSize failed\n");
+        ok(GetLastError() == 0xdeadbeef, "GetLastError failed: %u\n", GetLastError());
+        mem1 = HeapReAlloc(heap, 0, mem1, 1024);
+        ok(mem1 != NULL, "HeapReAlloc failed\n");
+
+        dwSize = HeapSize(heap, 0, mem1);
+        ok(dwSize == 1024, "HeapSize failed\n");
+
+        dwSize = HeapSize(heap, 0, mem2);
+        ok(dwSize == 16, "HeapSize failed\n");
+        ok(GetLastError() == 0xdeadbeef, "GetLastError failed: %u\n", GetLastError());
+
+        dwSize = HeapSize(heap, 0, mem3);
+        ok(dwSize == 16, "HeapSize failed\n");
+        ok(GetLastError() == 0xdeadbeef, "GetLastError failed: %u\n", GetLastError());
+
+        ok(HeapValidate(heap, 0, NULL), "HeapValidate failed\n");
+
+        ok(HeapFree(heap, 0, mem1), "HeapFree failed\n");
+        ok(HeapFree(heap, 0, mem2), "HeapFree failed\n");
+        ok(HeapFree(heap, 0, mem3), "HeapFree failed\n");
+
+        ok(HeapValidate(heap, 0, NULL), "HeapValidate failed\n");
+
+        ok(HeapDestroy(heap),"HeapDestroy failed\n");
+    }
 }
 
 
diff --git a/dlls/kernelbase/memory.c b/dlls/kernelbase/memory.c
index 7844b571e51..9a8af4d0b20 100644
--- a/dlls/kernelbase/memory.c
+++ b/dlls/kernelbase/memory.c
@@ -649,7 +649,12 @@ HLOCAL WINAPI DECLSPEC_HOTPATCH LocalAlloc( UINT flags, SIZE_T size )
 
     if (!(flags & LMEM_MOVEABLE)) /* pointer */
     {
-        ptr = HeapAlloc( GetProcessHeap(), heap_flags, size );
+        if (size >= 1024) ptr = HeapAlloc( GetProcessHeap(), heap_flags, size );
+        else
+        {
+            ptr = HeapAlloc( GetProcessHeap(), heap_flags, 1024 );
+            ptr = HeapReAlloc( GetProcessHeap(), heap_flags, ptr, size );
+        }
         TRACE( "(flags=%04x) returning %p\n",  flags, ptr );
         return ptr;
     }
diff --git a/dlls/msvcrt/heap.c b/dlls/msvcrt/heap.c
index 429a9e2ecda..16ce4bec3a3 100644
--- a/dlls/msvcrt/heap.c
+++ b/dlls/msvcrt/heap.c
@@ -530,7 +530,9 @@ int CDECL _set_sbh_threshold(size_t threshold)
 
   if(!sb_heap)
   {
+      ULONG hci = 2;
       sb_heap = HeapCreate(0, 0, 0);
+      HeapSetInformation(sb_heap, HeapCompatibilityInformation, &hci, sizeof(hci));
       if(!sb_heap)
           return 0;
   }
@@ -867,7 +869,9 @@ int CDECL strncpy_s(char *dest, size_t numberOfElements,
 
 BOOL msvcrt_init_heap(void)
 {
+    ULONG hci = 2;
     heap = HeapCreate(0, 0, 0);
+    HeapSetInformation(heap, HeapCompatibilityInformation, &hci, sizeof(hci));
     return heap != NULL;
 }
 
diff --git a/dlls/ntdll/Makefile.in b/dlls/ntdll/Makefile.in
index 185bc563e68..13c3a9743a9 100644
--- a/dlls/ntdll/Makefile.in
+++ b/dlls/ntdll/Makefile.in
@@ -19,6 +19,7 @@ C_SRCS = \
 	exception.c \
 	handletable.c \
 	heap.c \
+	heap_lfh.c \
 	large_int.c \
 	loader.c \
 	locale.c \
diff --git a/dlls/ntdll/heap.c b/dlls/ntdll/heap.c
index 346bcf3c10c..8a38cfbdf80 100644
--- a/dlls/ntdll/heap.c
+++ b/dlls/ntdll/heap.c
@@ -163,6 +163,8 @@ typedef struct tagHEAP
     ARENA_INUSE    **pending_free;  /* Ring buffer for pending free requests */
     RTL_CRITICAL_SECTION critSection; /* Critical section for serialization */
     FREE_LIST_ENTRY *freeList;      /* Free lists */
+    DWORD            freeMask[HEAP_NB_FREE_LISTS / (8 * sizeof(DWORD))];
+    int              extended_type; /* Extended heap type */
 } HEAP;
 
 #define HEAP_MAGIC       ((DWORD)('H' | ('E'<<8) | ('A'<<16) | ('P'<<24)))
@@ -171,12 +173,6 @@ typedef struct tagHEAP
 #define COMMIT_MASK          0xffff  /* bitmask for commit/decommit granularity */
 #define MAX_FREE_PENDING     1024    /* max number of free requests to delay */
 
-/* some undocumented flags (names are made up) */
-#define HEAP_PAGE_ALLOCS      0x01000000
-#define HEAP_VALIDATE         0x10000000
-#define HEAP_VALIDATE_ALL     0x20000000
-#define HEAP_VALIDATE_PARAMS  0x40000000
-
 static HEAP *processHeap;  /* main process heap */
 
 static BOOL HEAP_IsRealArena( HEAP *heapPtr, DWORD flags, LPCVOID block, BOOL quiet );
@@ -451,21 +447,26 @@ static HEAP *HEAP_GetPtr(
              HANDLE heap /* [in] Handle to the heap */
 ) {
     HEAP *heapPtr = heap;
+    BOOL ret;
+
     if (!heapPtr || (heapPtr->magic != HEAP_MAGIC))
     {
         ERR("Invalid heap %p!\n", heap );
         return NULL;
     }
-    if ((heapPtr->flags & HEAP_VALIDATE_ALL) && !HEAP_IsRealArena( heapPtr, 0, NULL, NOISY ))
+    if (!(heapPtr->flags & HEAP_VALIDATE_ALL)) return heapPtr;
+
+    if (!(heapPtr->flags & HEAP_NO_SERIALIZE)) RtlEnterCriticalSection( &heapPtr->critSection );
+    ret = HEAP_IsRealArena( heapPtr, heapPtr->flags, NULL, NOISY );
+    if (!(heapPtr->flags & HEAP_NO_SERIALIZE)) RtlLeaveCriticalSection( &heapPtr->critSection );
+
+    if (ret) return heapPtr;
+    if (TRACE_ON(heap))
     {
-        if (TRACE_ON(heap))
-        {
-            HEAP_Dump( heapPtr );
-            assert( FALSE );
-        }
-        return NULL;
+        HEAP_Dump( heapPtr );
+        assert( FALSE );
     }
-    return heapPtr;
+    return NULL;
 }
 
 
@@ -1331,15 +1332,8 @@ static BOOL HEAP_IsRealArena( HEAP *heapPtr,   /* [in] ptr to the heap */
                               *             does not complain    */
 {
     SUBHEAP *subheap;
-    BOOL ret = FALSE;
     const ARENA_LARGE *large_arena;
 
-    flags &= HEAP_NO_SERIALIZE;
-    flags |= heapPtr->flags;
-    /* calling HeapLock may result in infinite recursion, so do the critsect directly */
-    if (!(flags & HEAP_NO_SERIALIZE))
-        RtlEnterCriticalSection( &heapPtr->critSection );
-
     if (block)  /* only check this single memory block */
     {
         const ARENA_INUSE *arena = (const ARENA_INUSE *)block - 1;
@@ -1353,11 +1347,11 @@ static BOOL HEAP_IsRealArena( HEAP *heapPtr,   /* [in] ptr to the heap */
                     ERR("Heap %p: block %p is not inside heap\n", heapPtr, block );
                 else if (WARN_ON(heap))
                     WARN("Heap %p: block %p is not inside heap\n", heapPtr, block );
+                return FALSE;
             }
-            else ret = validate_large_arena( heapPtr, large_arena, quiet );
+            return validate_large_arena( heapPtr, large_arena, quiet );
         }
-        else ret = HEAP_ValidateInUseArena( subheap, arena, quiet );
-        goto done;
+        return HEAP_ValidateInUseArena( subheap, arena, quiet );
     }
 
     LIST_FOR_EACH_ENTRY( subheap, &heapPtr->subheap_list, SUBHEAP, entry )
@@ -1367,25 +1361,20 @@ static BOOL HEAP_IsRealArena( HEAP *heapPtr,   /* [in] ptr to the heap */
         {
             if (*(DWORD *)ptr & ARENA_FLAG_FREE)
             {
-                if (!HEAP_ValidateFreeArena( subheap, (ARENA_FREE *)ptr )) goto done;
+                if (!HEAP_ValidateFreeArena( subheap, (ARENA_FREE *)ptr )) return FALSE;
                 ptr += sizeof(ARENA_FREE) + (*(DWORD *)ptr & ARENA_SIZE_MASK);
             }
             else
             {
-                if (!HEAP_ValidateInUseArena( subheap, (ARENA_INUSE *)ptr, NOISY )) goto done;
+                if (!HEAP_ValidateInUseArena( subheap, (ARENA_INUSE *)ptr, NOISY )) return FALSE;
                 ptr += sizeof(ARENA_INUSE) + (*(DWORD *)ptr & ARENA_SIZE_MASK);
             }
         }
     }
 
     LIST_FOR_EACH_ENTRY( large_arena, &heapPtr->large_list, ARENA_LARGE, entry )
-        if (!validate_large_arena( heapPtr, large_arena, quiet )) goto done;
-
-    ret = TRUE;
-
-done:
-    if (!(flags & HEAP_NO_SERIALIZE)) RtlLeaveCriticalSection( &heapPtr->critSection );
-    return ret;
+        if (!validate_large_arena( heapPtr, large_arena, quiet )) return FALSE;
+    return TRUE;
 }
 
 
@@ -1512,6 +1501,7 @@ static void heap_set_debug_flags( HANDLE handle )
                                               MAX_FREE_PENDING * sizeof(*heap->pending_free) );
         heap->pending_pos = 0;
     }
+    HEAP_lfh_set_debug_flags( flags );
 }
 
 
@@ -1555,11 +1545,13 @@ HANDLE WINAPI RtlCreateHeap( ULONG flags, PVOID addr, SIZE_T totalSize, SIZE_T c
         HEAP *heapPtr = subheap->heap;
         RtlEnterCriticalSection( &processHeap->critSection );
         list_add_head( &processHeap->entry, &heapPtr->entry );
+        heapPtr->extended_type = HEAP_STD;
         RtlLeaveCriticalSection( &processHeap->critSection );
     }
     else if (!addr)
     {
         processHeap = subheap->heap;  /* assume the first heap we create is the process main heap */
+        processHeap->extended_type = HEAP_STD;
         list_init( &processHeap->entry );
     }
 
@@ -1650,11 +1642,9 @@ HANDLE WINAPI RtlDestroyHeap( HANDLE heap )
  */
 void * WINAPI DECLSPEC_HOTPATCH RtlAllocateHeap( HANDLE heap, ULONG flags, SIZE_T size )
 {
-    ARENA_FREE *pArena;
-    ARENA_INUSE *pInUse;
-    SUBHEAP *subheap;
+    NTSTATUS status;
     HEAP *heapPtr = HEAP_GetPtr( heap );
-    SIZE_T rounded_size;
+    void *ptr;
 
     /* Validate the parameters */
 
@@ -1662,34 +1652,47 @@ void * WINAPI DECLSPEC_HOTPATCH RtlAllocateHeap( HANDLE heap, ULONG flags, SIZE_
     flags &= HEAP_GENERATE_EXCEPTIONS | HEAP_NO_SERIALIZE | HEAP_ZERO_MEMORY;
     flags |= heapPtr->flags;
     rounded_size = ROUND_SIZE(size) + HEAP_TAIL_EXTRA_SIZE( flags );
-    if (rounded_size < size)  /* overflow */
+
+    switch (heapPtr->extended_type)
     {
-        if (flags & HEAP_GENERATE_EXCEPTIONS) RtlRaiseStatus( STATUS_NO_MEMORY );
-        return NULL;
+    case HEAP_LFH:
+        if (!(status = HEAP_lfh_allocate( heap, flags, size, &ptr ))) break;
+        /* fallthrough */
+    default:
+        if (!(flags & HEAP_NO_SERIALIZE)) enter_critical_section( &heapPtr->critSection );
+        status = HEAP_std_allocate( heap, flags, size, &ptr );
+        if (!(flags & HEAP_NO_SERIALIZE)) leave_critical_section( &heapPtr->critSection );
+        break;
     }
-    if (rounded_size < HEAP_MIN_DATA_SIZE) rounded_size = HEAP_MIN_DATA_SIZE;
 
-    if (!(flags & HEAP_NO_SERIALIZE)) RtlEnterCriticalSection( &heapPtr->critSection );
+    TRACE("(%p,%08x,%08lx), status %#x, ptr %p\n", heapPtr, flags, size, status, ptr );
+    if (!status) return ptr;
+    if ((flags & HEAP_GENERATE_EXCEPTIONS) && status == STATUS_NO_MEMORY) RtlRaiseStatus( status );
+    RtlSetLastWin32ErrorAndNtStatusFromNtStatus( status );
+    return NULL;
+}
+
+NTSTATUS HEAP_std_allocate( HANDLE heap, ULONG flags, SIZE_T size, void **out )
+{
+    HEAP *heapPtr = heap;
+    ARENA_FREE *pArena;
+    ARENA_INUSE *pInUse;
+    SUBHEAP *subheap;
+    SIZE_T rounded_size;
+
+    rounded_size = ROUND_SIZE(size) + HEAP_TAIL_EXTRA_SIZE;
+    if (rounded_size < size) return STATUS_NO_MEMORY; /* overflow */
+    if (rounded_size < HEAP_MIN_DATA_SIZE) rounded_size = HEAP_MIN_DATA_SIZE;
 
     if (rounded_size >= HEAP_MIN_LARGE_BLOCK_SIZE && (flags & HEAP_GROWABLE))
     {
-        void *ret = allocate_large_block( heap, flags, size );
-        if (!(flags & HEAP_NO_SERIALIZE)) RtlLeaveCriticalSection( &heapPtr->critSection );
-        if (!ret && (flags & HEAP_GENERATE_EXCEPTIONS)) RtlRaiseStatus( STATUS_NO_MEMORY );
-        TRACE("(%p,%08x,%08lx): returning %p\n", heap, flags, size, ret );
-        return ret;
+        if (!(*out = allocate_large_block( heapPtr, flags, size ))) return STATUS_NO_MEMORY;
+        return STATUS_SUCCESS;
     }
 
     /* Locate a suitable free block */
 
-    if (!(pArena = HEAP_FindFreeBlock( heapPtr, rounded_size, &subheap )))
-    {
-        TRACE("(%p,%08x,%08lx): returning NULL\n",
-                  heap, flags, size  );
-        if (!(flags & HEAP_NO_SERIALIZE)) RtlLeaveCriticalSection( &heapPtr->critSection );
-        if (flags & HEAP_GENERATE_EXCEPTIONS) RtlRaiseStatus( STATUS_NO_MEMORY );
-        return NULL;
-    }
+    if (!(pArena = HEAP_FindFreeBlock( heapPtr, rounded_size, &subheap ))) return STATUS_NO_MEMORY;
 
     /* Remove the arena from the free list */
 
@@ -1712,10 +1715,8 @@ void * WINAPI DECLSPEC_HOTPATCH RtlAllocateHeap( HANDLE heap, ULONG flags, SIZE_
     notify_alloc( pInUse + 1, size, flags & HEAP_ZERO_MEMORY );
     initialize_block( pInUse + 1, size, pInUse->unused_bytes, flags );
 
-    if (!(flags & HEAP_NO_SERIALIZE)) RtlLeaveCriticalSection( &heapPtr->critSection );
-
-    TRACE("(%p,%08x,%08lx): returning %p\n", heap, flags, size, pInUse + 1 );
-    return pInUse + 1;
+    *out = pInUse + 1;
+    return STATUS_SUCCESS;
 }
 
 
@@ -1735,8 +1736,7 @@ void * WINAPI DECLSPEC_HOTPATCH RtlAllocateHeap( HANDLE heap, ULONG flags, SIZE_
  */
 BOOLEAN WINAPI DECLSPEC_HOTPATCH RtlFreeHeap( HANDLE heap, ULONG flags, void *ptr )
 {
-    ARENA_INUSE *pInUse;
-    SUBHEAP *subheap;
+    NTSTATUS status;
     HEAP *heapPtr;
 
     /* Validate the parameters */
@@ -1752,29 +1752,42 @@ BOOLEAN WINAPI DECLSPEC_HOTPATCH RtlFreeHeap( HANDLE heap, ULONG flags, void *pt
 
     flags &= HEAP_NO_SERIALIZE;
     flags |= heapPtr->flags;
-    if (!(flags & HEAP_NO_SERIALIZE)) RtlEnterCriticalSection( &heapPtr->critSection );
+    switch (heapPtr->extended_type)
+    {
+    case HEAP_LFH:
+        if (!(status = HEAP_lfh_allocate( heap, flags, size, &ptr ))) break;
+        /* fallthrough */
+    default:
+        if (!(flags & HEAP_NO_SERIALIZE)) enter_critical_section( &heapPtr->critSection );
+        status = HEAP_std_allocate( heap, flags, size, &ptr );
+        if (!(flags & HEAP_NO_SERIALIZE)) leave_critical_section( &heapPtr->critSection );
+        break;
+    }
 
+    TRACE("(%p,%08x,%p), status %#x\n", heapPtr, flags, ptr, status );
+    if (!status) return TRUE;
+    RtlSetLastWin32ErrorAndNtStatusFromNtStatus( status );
+    return FALSE;
+}
+
+NTSTATUS HEAP_std_free( HANDLE heap, ULONG flags, void *ptr )
+{
+    ARENA_INUSE *pInUse;
+    HEAP *heapPtr = heap;
+    SUBHEAP *subheap;
     /* Inform valgrind we are trying to free memory, so it can throw up an error message */
     notify_free( ptr );
 
     /* Some sanity checks */
     pInUse  = (ARENA_INUSE *)ptr - 1;
-    if (!validate_block_pointer( heapPtr, &subheap, pInUse )) goto error;
+    if (!validate_block_pointer( heapPtr, &subheap, pInUse )) return STATUS_INVALID_PARAMETER;
 
     if (!subheap)
         free_large_block( heapPtr, flags, ptr );
     else
         HEAP_MakeInUseBlockFree( subheap, pInUse );
 
-    if (!(flags & HEAP_NO_SERIALIZE)) RtlLeaveCriticalSection( &heapPtr->critSection );
-    TRACE("(%p,%08x,%p): returning TRUE\n", heap, flags, ptr );
-    return TRUE;
-
-error:
-    if (!(flags & HEAP_NO_SERIALIZE)) RtlLeaveCriticalSection( &heapPtr->critSection );
-    RtlSetLastWin32ErrorAndNtStatusFromNtStatus( STATUS_INVALID_PARAMETER );
-    TRACE("(%p,%08x,%p): returning FALSE\n", heap, flags, ptr );
-    return FALSE;
+    return STATUS_SUCCESS;
 }
 
 
@@ -1795,10 +1808,8 @@ error:
  */
 PVOID WINAPI RtlReAllocateHeap( HANDLE heap, ULONG flags, PVOID ptr, SIZE_T size )
 {
-    ARENA_INUSE *pArena;
+    NTSTATUS status;
     HEAP *heapPtr;
-    SUBHEAP *subheap;
-    SIZE_T oldBlockSize, oldActualSize, rounded_size;
     void *ret;
 
     if (!ptr) return NULL;
@@ -1813,18 +1824,42 @@ PVOID WINAPI RtlReAllocateHeap( HANDLE heap, ULONG flags, PVOID ptr, SIZE_T size
     flags &= HEAP_GENERATE_EXCEPTIONS | HEAP_NO_SERIALIZE | HEAP_ZERO_MEMORY |
              HEAP_REALLOC_IN_PLACE_ONLY;
     flags |= heapPtr->flags;
-    if (!(flags & HEAP_NO_SERIALIZE)) RtlEnterCriticalSection( &heapPtr->critSection );
+    switch (heapPtr->extended_type)
+    {
+    case HEAP_LFH:
+        if (!(status = HEAP_lfh_reallocate( heap, flags, ptr, size, &ret ))) break;
+        /* fallthrough */
+    default:
+        if (!(flags & HEAP_NO_SERIALIZE)) enter_critical_section( &heapPtr->critSection );
+        status = HEAP_std_reallocate( heap, flags, ptr, size, &ret );
+        if (!(flags & HEAP_NO_SERIALIZE)) leave_critical_section( &heapPtr->critSection );
+        break;
+    }
 
+    TRACE("(%p,%08x,%p,%08lx): returning %p, status %#x\n", heapPtr, flags, ptr, size, ret, status );
+    if (!status) return ret;
+    if ((flags & HEAP_GENERATE_EXCEPTIONS) && (status == STATUS_NO_MEMORY)) RtlRaiseStatus( status );
+    RtlSetLastWin32ErrorAndNtStatusFromNtStatus( status );
+    return NULL;
+}
+
+NTSTATUS HEAP_std_reallocate( HANDLE heap, ULONG flags, void *ptr, SIZE_T size, void **out )
+{
+    HEAP *heapPtr = heap;
+    ARENA_INUSE *pArena;
+    SUBHEAP *subheap;
+    SIZE_T oldBlockSize, oldActualSize, rounded_size;
+    
     rounded_size = ROUND_SIZE(size) + HEAP_TAIL_EXTRA_SIZE(flags);
-    if (rounded_size < size) goto oom;  /* overflow */
+    if (rounded_size < size) return STATUS_NO_MEMORY; /* overflow */
     if (rounded_size < HEAP_MIN_DATA_SIZE) rounded_size = HEAP_MIN_DATA_SIZE;
 
     pArena = (ARENA_INUSE *)ptr - 1;
-    if (!validate_block_pointer( heapPtr, &subheap, pArena )) goto error;
+    if (!validate_block_pointer( heapPtr, &subheap, pArena )) return STATUS_INVALID_PARAMETER;
     if (!subheap)
     {
-        if (!(ret = realloc_large_block( heapPtr, flags, ptr, size ))) goto oom;
-        goto done;
+        if (!(*out = realloc_large_block( heapPtr, flags, ptr, size ))) return STATUS_NO_MEMORY;
+        return STATUS_SUCCESS;
     }
 
     /* Check if we need to grow the block */
@@ -1837,12 +1872,12 @@ PVOID WINAPI RtlReAllocateHeap( HANDLE heap, ULONG flags, PVOID ptr, SIZE_T size
 
         if (rounded_size >= HEAP_MIN_LARGE_BLOCK_SIZE && (flags & HEAP_GROWABLE))
         {
-            if (flags & HEAP_REALLOC_IN_PLACE_ONLY) goto oom;
-            if (!(ret = allocate_large_block( heapPtr, flags, size ))) goto oom;
-            memcpy( ret, pArena + 1, oldActualSize );
+            if (flags & HEAP_REALLOC_IN_PLACE_ONLY) return STATUS_NO_MEMORY;
+            if (!(*out = allocate_large_block( heapPtr, flags, size ))) return STATUS_NO_MEMORY;
+            memcpy( *out, pArena + 1, oldActualSize );
             notify_free( pArena + 1 );
             HEAP_MakeInUseBlockFree( subheap, pArena );
-            goto done;
+            return STATUS_SUCCESS;
         }
         if ((pNext < (char *)subheap->base + subheap->size) &&
             (*(DWORD *)pNext & ARENA_FLAG_FREE) &&
@@ -1852,7 +1887,7 @@ PVOID WINAPI RtlReAllocateHeap( HANDLE heap, ULONG flags, PVOID ptr, SIZE_T size
             ARENA_FREE *pFree = (ARENA_FREE *)pNext;
             list_remove( &pFree->entry );
             pArena->size += (pFree->size & ARENA_SIZE_MASK) + sizeof(*pFree);
-            if (!HEAP_Commit( subheap, pArena, rounded_size )) goto oom;
+            if (!HEAP_Commit( subheap, pArena, rounded_size )) return STATUS_NO_MEMORY;
             notify_realloc( pArena + 1, oldActualSize, size );
             HEAP_ShrinkBlock( subheap, pArena, rounded_size );
         }
@@ -1864,7 +1899,7 @@ PVOID WINAPI RtlReAllocateHeap( HANDLE heap, ULONG flags, PVOID ptr, SIZE_T size
 
             if ((flags & HEAP_REALLOC_IN_PLACE_ONLY) ||
                 !(pNew = HEAP_FindFreeBlock( heapPtr, rounded_size, &newsubheap )))
-                goto oom;
+                return STATUS_NO_MEMORY;
 
             /* Build the in-use arena */
 
@@ -1905,24 +1940,8 @@ PVOID WINAPI RtlReAllocateHeap( HANDLE heap, ULONG flags, PVOID ptr, SIZE_T size
 
     /* Return the new arena */
 
-    ret = pArena + 1;
-done:
-    if (!(flags & HEAP_NO_SERIALIZE)) RtlLeaveCriticalSection( &heapPtr->critSection );
-    TRACE("(%p,%08x,%p,%08lx): returning %p\n", heap, flags, ptr, size, ret );
-    return ret;
-
-oom:
-    if (!(flags & HEAP_NO_SERIALIZE)) RtlLeaveCriticalSection( &heapPtr->critSection );
-    if (flags & HEAP_GENERATE_EXCEPTIONS) RtlRaiseStatus( STATUS_NO_MEMORY );
-    RtlSetLastWin32ErrorAndNtStatusFromNtStatus( STATUS_NO_MEMORY );
-    TRACE("(%p,%08x,%p,%08lx): returning NULL\n", heap, flags, ptr, size );
-    return NULL;
-
-error:
-    if (!(flags & HEAP_NO_SERIALIZE)) RtlLeaveCriticalSection( &heapPtr->critSection );
-    RtlSetLastWin32ErrorAndNtStatusFromNtStatus( STATUS_INVALID_PARAMETER );
-    TRACE("(%p,%08x,%p,%08lx): returning NULL\n", heap, flags, ptr, size );
-    return NULL;
+    *out = pArena + 1;
+    return STATUS_SUCCESS;
 }
 
 
@@ -2010,10 +2029,9 @@ BOOLEAN WINAPI RtlUnlockHeap( HANDLE heap )
  */
 SIZE_T WINAPI RtlSizeHeap( HANDLE heap, ULONG flags, const void *ptr )
 {
-    SIZE_T ret;
-    const ARENA_INUSE *pArena;
-    SUBHEAP *subheap;
     HEAP *heapPtr = HEAP_GetPtr( heap );
+    NTSTATUS status;
+    SIZE_T size = ~(SIZE_T)0;
 
     if (!heapPtr)
     {
@@ -2022,27 +2040,34 @@ SIZE_T WINAPI RtlSizeHeap( HANDLE heap, ULONG flags, const void *ptr )
     }
     flags &= HEAP_NO_SERIALIZE;
     flags |= heapPtr->flags;
-    if (!(flags & HEAP_NO_SERIALIZE)) RtlEnterCriticalSection( &heapPtr->critSection );
-
-    pArena = (const ARENA_INUSE *)ptr - 1;
-    if (!validate_block_pointer( heapPtr, &subheap, pArena ))
+    switch (heapPtr->extended_type)
     {
-        RtlSetLastWin32ErrorAndNtStatusFromNtStatus( STATUS_INVALID_PARAMETER );
-        ret = ~(SIZE_T)0;
-    }
-    else if (!subheap)
-    {
-        const ARENA_LARGE *large_arena = (const ARENA_LARGE *)ptr - 1;
-        ret = large_arena->data_size;
-    }
-    else
-    {
-        ret = (pArena->size & ARENA_SIZE_MASK) - pArena->unused_bytes;
+    case HEAP_LFH:
+        if (!(status = HEAP_lfh_get_allocated_size( heap, flags, ptr, &size ))) break;
+        /* fallthrough */
+    default:
+        if (!(flags & HEAP_NO_SERIALIZE)) enter_critical_section( &heapPtr->critSection );
+        status = HEAP_std_get_allocated_size( heap, flags, ptr, &size );
+        if (!(flags & HEAP_NO_SERIALIZE)) leave_critical_section( &heapPtr->critSection );
+        break;
     }
-    if (!(flags & HEAP_NO_SERIALIZE)) RtlLeaveCriticalSection( &heapPtr->critSection );
 
-    TRACE("(%p,%08x,%p): returning %08lx\n", heap, flags, ptr, ret );
-    return ret;
+    TRACE("(%p,%08x,%p): status %#x, size %08lx\n", heapPtr, flags, ptr, status, size );
+    if (!status) return size;
+    RtlSetLastWin32ErrorAndNtStatusFromNtStatus( status );
+    return ~(SIZE_T)0;
+}
+
+NTSTATUS HEAP_std_get_allocated_size( HANDLE heap, ULONG flags, const void *ptr, SIZE_T *out )
+{
+    const ARENA_LARGE *large_arena = (const ARENA_LARGE *)ptr - 1;
+    const ARENA_INUSE *arena = (const ARENA_INUSE *)ptr - 1;
+    HEAP *heapPtr = heap;
+    SUBHEAP *subheap;
+    if (!validate_block_pointer( heapPtr, &subheap, arena )) return STATUS_INVALID_PARAMETER;
+    else if (!subheap) *out = large_arena->data_size;
+    else *out = (arena->size & ARENA_SIZE_MASK) - arena->unused_bytes;
+    return STATUS_SUCCESS;
 }
 
 
@@ -2062,9 +2087,26 @@ SIZE_T WINAPI RtlSizeHeap( HANDLE heap, ULONG flags, const void *ptr )
  */
 BOOLEAN WINAPI RtlValidateHeap( HANDLE heap, ULONG flags, LPCVOID ptr )
 {
+    NTSTATUS status = STATUS_SUCCESS;
     HEAP *heapPtr = HEAP_GetPtr( heap );
     if (!heapPtr) return FALSE;
-    return HEAP_IsRealArena( heapPtr, flags, ptr, QUIET );
+    flags &= HEAP_NO_SERIALIZE;
+    flags |= heapPtr->flags;
+
+    switch (heapPtr->extended_type)
+    {
+    case HEAP_LFH:
+        if (!HEAP_lfh_validate( heapPtr, flags, ptr )) break;
+        /* fallthrough */
+    default:
+        if (!(flags & HEAP_NO_SERIALIZE)) enter_critical_section( &heapPtr->critSection );
+        if (!HEAP_IsRealArena( heapPtr, flags, ptr, QUIET )) status = STATUS_INVALID_PARAMETER;
+        if (!(flags & HEAP_NO_SERIALIZE)) leave_critical_section( &heapPtr->critSection );
+        break;
+    }
+
+    TRACE("(%p,%08x,%p): status %#x\n", heapPtr, flags, ptr, status );
+    return !status;
 }
 
 
@@ -2232,6 +2274,13 @@ ULONG WINAPI RtlGetProcessHeaps( ULONG count, HANDLE *heaps )
 NTSTATUS WINAPI RtlQueryHeapInformation( HANDLE heap, HEAP_INFORMATION_CLASS info_class,
                                          PVOID info, SIZE_T size_in, PSIZE_T size_out)
 {
+    HEAP *heapPtr;
+
+    TRACE("%p %d %p %ld\n", heap, info_class, info, size_in);
+
+    if (!(heapPtr = HEAP_GetPtr( heap )))
+        return STATUS_INVALID_PARAMETER;
+    
     switch (info_class)
     {
     case HeapCompatibilityInformation:
@@ -2240,7 +2289,7 @@ NTSTATUS WINAPI RtlQueryHeapInformation( HANDLE heap, HEAP_INFORMATION_CLASS inf
         if (size_in < sizeof(ULONG))
             return STATUS_BUFFER_TOO_SMALL;
 
-        *(ULONG *)info = 0; /* standard heap */
+        *(ULONG *)info = heapPtr->extended_type;
         return STATUS_SUCCESS;
 
     default:
@@ -2254,6 +2303,43 @@ NTSTATUS WINAPI RtlQueryHeapInformation( HANDLE heap, HEAP_INFORMATION_CLASS inf
  */
 NTSTATUS WINAPI RtlSetHeapInformation( HANDLE heap, HEAP_INFORMATION_CLASS info_class, PVOID info, SIZE_T size)
 {
-    FIXME("%p %d %p %ld stub\n", heap, info_class, info, size);
-    return STATUS_SUCCESS;
+    TRACE("%p %d %p %ld stub\n", heap, info_class, info, size);
+
+    switch (info_class)
+    {
+    case HeapEnableTerminationOnCorruption:
+        FIXME("unimplemented HeapEnableTerminationOnCorruption\n");
+        return STATUS_SUCCESS;
+
+    case HeapCompatibilityInformation:
+    {
+        HEAP *heapPtr;
+        heapPtr = HEAP_GetPtr( heap );
+
+        if (size < sizeof(ULONG))
+            return STATUS_BUFFER_TOO_SMALL;
+
+        if (heapPtr->extended_type != HEAP_STD)
+            return STATUS_UNSUCCESSFUL;
+
+        if (*(ULONG *)info != HEAP_STD &&
+            *(ULONG *)info != HEAP_LFH)
+        {
+            FIXME("unimplemented HeapCompatibilityInformation %d\n", *(ULONG *)info);
+            return STATUS_SUCCESS;
+        }
+
+        heapPtr->extended_type = *(ULONG *)info;
+        return STATUS_SUCCESS;
+    }
+
+    default:
+        FIXME("Unknown heap information class %u\n", info_class);
+        return STATUS_INVALID_INFO_CLASS;
+    }
+}
+
+void HEAP_notify_thread_destroy( BOOLEAN last )
+{
+    HEAP_lfh_notify_thread_destroy( last );
 }
diff --git a/dlls/ntdll/heap_lfh.c b/dlls/ntdll/heap_lfh.c
new file mode 100644
index 00000000000..5e38d2d0a3b
--- /dev/null
+++ b/dlls/ntdll/heap_lfh.c
@@ -0,0 +1,1140 @@
+/*
+ * Wine Low Fragmentation Heap
+ *
+ * Copyright 2020 Remi Bernon for CodeWeavers
+ *
+ * This library is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU Lesser General Public
+ * License as published by the Free Software Foundation; either
+ * version 2.1 of the License, or (at your option) any later version.
+ *
+ * This library is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * Lesser General Public License for more details.
+ *
+ * You should have received a copy of the GNU Lesser General Public
+ * License along with this library; if not, write to the Free Software
+ * Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301, USA
+ */
+
+#include "ntstatus.h"
+#define WIN32_NO_STATUS
+#include "wine/list.h"
+#include "wine/debug.h"
+
+#include "ntdll_misc.h"
+
+#if defined(__GNUC__) || defined(__clang__)
+#define likely(x) __builtin_expect(!!(x), 1)
+#define unlikely(x) __builtin_expect(!!(x), 0)
+#else
+#define likely(x) x
+#define unlikely(x) x
+#endif
+
+
+WINE_DEFAULT_DEBUG_CHANNEL(heap);
+
+typedef struct LFH_ptr LFH_ptr;
+typedef struct LFH_block LFH_block;
+typedef enum LFH_block_type LFH_block_type;
+typedef struct LFH_arena LFH_arena;
+typedef struct LFH_class LFH_class;
+typedef struct LFH_heap LFH_heap;
+typedef struct LFH_slist LFH_slist;
+
+#define ARENA_HEADER_SIZE (sizeof(LFH_arena))
+
+#define LARGE_ARENA_SIZE 0x400000 /* 4MiB */
+#define LARGE_ARENA_MASK (LARGE_ARENA_SIZE - 1)
+
+#define BLOCK_ARENA_SIZE 0x10000 /* 64kiB */
+#define BLOCK_ARENA_MASK (BLOCK_ARENA_SIZE - 1)
+
+#define SMALL_CLASS_STEP     0x20
+#define SMALL_CLASS_MASK     (SMALL_CLASS_STEP - 1)
+#define SMALL_CLASS_MIN_SIZE SMALL_CLASS_STEP
+#define SMALL_CLASS_MAX_SIZE 0x800
+#define SMALL_CLASS_COUNT    ((SMALL_CLASS_MAX_SIZE - SMALL_CLASS_MIN_SIZE) / SMALL_CLASS_STEP + 1)
+#define SMALL_CLASS_FIRST    0
+#define SMALL_CLASS_LAST     (SMALL_CLASS_FIRST + SMALL_CLASS_COUNT - 1)
+
+#define MEDIUM_CLASS_STEP     (16 * SMALL_CLASS_STEP)
+#define MEDIUM_CLASS_MASK     (MEDIUM_CLASS_STEP - 1)
+#define MEDIUM_CLASS_MIN_SIZE SMALL_CLASS_MAX_SIZE
+#define MEDIUM_CLASS_MAX_SIZE ((BLOCK_ARENA_SIZE - ARENA_HEADER_SIZE - ARENA_HEADER_SIZE) / 2)
+#define MEDIUM_CLASS_COUNT    ((MEDIUM_CLASS_MAX_SIZE - MEDIUM_CLASS_MIN_SIZE + MEDIUM_CLASS_MASK) / MEDIUM_CLASS_STEP + 1)
+#define MEDIUM_CLASS_FIRST    (SMALL_CLASS_LAST + 1)
+#define MEDIUM_CLASS_LAST     (MEDIUM_CLASS_FIRST + MEDIUM_CLASS_COUNT - 1)
+
+#define LARGE_CLASS_STEP      BLOCK_ARENA_SIZE
+#define LARGE_CLASS_MASK      (LARGE_CLASS_STEP - 1)
+#define LARGE_CLASS_MIN_SIZE  (BLOCK_ARENA_SIZE - ARENA_HEADER_SIZE)
+#define LARGE_CLASS_MAX_SIZE  (LARGE_ARENA_SIZE / 2 - ARENA_HEADER_SIZE) /* we need an arena header for every large block */
+#define LARGE_CLASS_COUNT     ((LARGE_CLASS_MAX_SIZE - LARGE_CLASS_MIN_SIZE) / LARGE_CLASS_STEP + 1)
+#define LARGE_CLASS_FIRST     0
+#define LARGE_CLASS_LAST      (LARGE_CLASS_FIRST + LARGE_CLASS_COUNT - 1)
+
+#define TOTAL_BLOCK_CLASS_COUNT (MEDIUM_CLASS_LAST + 1)
+#define TOTAL_LARGE_CLASS_COUNT (LARGE_CLASS_LAST + 1)
+
+struct LFH_slist
+{
+    LFH_slist *next;
+};
+
+static inline void LFH_slist_push(LFH_slist **list, LFH_slist *entry)
+{
+    /* There will be no ABA issue here, other threads can only replace
+     * list->next with a different entry, or NULL. */
+    entry->next = __atomic_load_n(list, __ATOMIC_RELAXED);
+    while (!__atomic_compare_exchange_n(list, &entry->next, entry, 0, __ATOMIC_RELEASE, __ATOMIC_ACQUIRE));
+}
+
+static inline LFH_slist *LFH_slist_flush(LFH_slist **list)
+{
+    if (!__atomic_load_n(list, __ATOMIC_RELAXED)) return NULL;
+    return __atomic_exchange_n(list, NULL, __ATOMIC_ACQUIRE);
+}
+
+/* be sure to keep these different from ARENA_INUSE magic */
+enum LFH_block_type
+{
+    LFH_block_type_used = 0xa55a5aa5a55a5aa5ul,
+    LFH_block_type_free = 0xc33c3cc3c33c3cc3ul,
+};
+
+struct DECLSPEC_ALIGN(16) LFH_block
+{
+    union
+    {
+        ssize_t next_free;
+        LFH_slist entry_defer;
+        size_t alloc_size;
+    };
+
+    LFH_block_type type;
+};
+
+C_ASSERT(sizeof(LFH_block) == 0x10);
+C_ASSERT(offsetof(LFH_block, entry_defer) == 0);
+
+struct DECLSPEC_ALIGN(16) LFH_arena
+{
+    ssize_t next_free;
+    LFH_arena *class_entry;
+
+    union
+    {
+        LFH_arena *parent;
+        LFH_class *class;
+    };
+
+    union
+    {
+        size_t huge_size;
+        size_t used_count;
+    };
+};
+
+#ifdef _WIN64
+C_ASSERT(sizeof(LFH_arena) == 0x20);
+#else
+C_ASSERT(sizeof(LFH_arena) == 0x10);
+#endif
+
+struct LFH_class
+{
+    LFH_arena *next;
+    size_t     size;
+};
+
+struct LFH_heap
+{
+    LFH_slist *list_defer;
+    LFH_arena *cached_large_arena;
+
+    LFH_class block_class[TOTAL_BLOCK_CLASS_COUNT];
+    LFH_class large_class[TOTAL_LARGE_CLASS_COUNT];
+
+    SLIST_ENTRY entry_orphan;
+#ifdef _WIN64
+    void *pad[0xc2];
+#else
+    void *pad[0xc3];
+#endif
+};
+
+C_ASSERT(TOTAL_BLOCK_CLASS_COUNT == 0x7d);
+C_ASSERT(TOTAL_LARGE_CLASS_COUNT == 0x20);
+
+/* arena->class/arena->parent pointer low bits are used to discriminate between the two */
+C_ASSERT(offsetof(LFH_heap, block_class[0]) > 0);
+C_ASSERT(offsetof(LFH_heap, large_class[TOTAL_LARGE_CLASS_COUNT]) < BLOCK_ARENA_SIZE);
+
+/* helpers to retrieve parent arena from a child, or class pointer from a large or block arena */
+static inline LFH_arena *LFH_parent_from_arena(const LFH_arena *arena)
+{
+    if (!arena->parent) return (LFH_arena *)arena;
+    if (!((UINT_PTR)(arena)->parent & BLOCK_ARENA_MASK)) return arena->parent;
+    return (LFH_arena *)arena;
+}
+
+static inline LFH_class *LFH_class_from_arena(const LFH_arena *arena)
+{
+    const LFH_arena *parent = LFH_parent_from_arena(arena);
+    if ((UINT_PTR)parent->class & BLOCK_ARENA_MASK) return parent->class;
+    return NULL;
+}
+
+/* make sure its aligns to power of two so we can mask class pointers in LFH_heap_from_arena */
+#ifdef _WIN64
+C_ASSERT(sizeof(LFH_heap) == 0x1000);
+#else
+C_ASSERT(sizeof(LFH_heap) == 0x800);
+#endif
+
+/* helper to retrieve the heap from an arena, using its class pointer */
+static inline LFH_heap *LFH_heap_from_arena(const LFH_arena *arena)
+{
+    LFH_class *class = LFH_class_from_arena(arena);
+    return (LFH_heap *)((UINT_PTR)class & ~(sizeof(LFH_heap) - 1));
+}
+
+/* helpers to retrieve block pointers to the containing block or large (maybe child) arena */
+static inline LFH_arena *LFH_large_arena_from_block(const LFH_block *block)
+{
+    return (LFH_arena *)((UINT_PTR)block & ~BLOCK_ARENA_MASK);
+}
+
+static inline LFH_arena *LFH_block_arena_from_block(const LFH_block *block)
+{
+    return LFH_large_arena_from_block(block) + 1;
+}
+
+static inline LFH_arena *LFH_arena_from_block(const LFH_block *block)
+{
+    LFH_arena *block_arena = LFH_block_arena_from_block(block);
+    if (block_arena == (LFH_arena *)block) return LFH_large_arena_from_block(block);
+    return block_arena;
+}
+
+/* helpers to translate between data pointer and LFH_block header */
+static inline LFH_block *LFH_block_from_ptr(const LFH_ptr *ptr)
+{
+    return ((LFH_block *)ptr) - 1;
+}
+
+static inline void *LFH_ptr_from_block(const LFH_block *block)
+{
+    return (LFH_ptr *)(block + 1);
+}
+
+static inline size_t LFH_block_get_class_size(const LFH_block *block)
+{
+    const LFH_arena *arena = LFH_arena_from_block(block);
+    const LFH_class *class = LFH_class_from_arena(arena);
+    if (class) return class->size;
+    return arena->huge_size;
+}
+
+static inline size_t LFH_block_get_alloc_size(const LFH_block *block, ULONG flags)
+{
+    return block->alloc_size;
+}
+
+static inline size_t LFH_get_class_size(ULONG flags, size_t size)
+{
+    size_t extra = sizeof(LFH_block) + 16;
+    if (size + extra < size) return ~(size_t)0;
+    return size + extra;
+}
+
+static inline void *LFH_memory_allocate(size_t size)
+{
+    void *addr = NULL;
+    SIZE_T alloc_size = size;
+
+    if (NtAllocateVirtualMemory(NtCurrentProcess(), (void **)&addr, 0, &alloc_size,
+                                MEM_RESERVE | MEM_COMMIT, PAGE_READWRITE))
+        return NULL;
+
+    return addr;
+}
+
+static inline BOOLEAN LFH_memory_deallocate(void *addr, size_t size)
+{
+    SIZE_T release_size = 0;
+
+    if (NtFreeVirtualMemory(NtCurrentProcess(), &addr, &release_size, MEM_RELEASE))
+        return FALSE;
+
+    return TRUE;
+}
+
+static inline LFH_block *LFH_arena_get_block(const LFH_arena *arena, size_t offset)
+{
+    return (LFH_block *)((UINT_PTR)arena + offset);
+}
+
+static inline void LFH_arena_push_block(LFH_arena *arena, LFH_block *block)
+{
+    block->type = LFH_block_type_free;
+    block->next_free = arena->next_free;
+    arena->next_free = (UINT_PTR)block - (UINT_PTR)arena;
+    arena->used_count--;
+}
+
+static inline LFH_block *LFH_arena_pop_block(LFH_arena *arena)
+{
+    if (arena->next_free > 0)
+    {
+        LFH_block *block = LFH_arena_get_block(arena, arena->next_free);
+        arena->next_free = block->next_free;
+        arena->used_count++;
+        return block;
+    }
+    else
+    {
+        LFH_arena *child, *large_arena = LFH_large_arena_from_block((LFH_block *)arena);
+        LFH_class *class = LFH_class_from_arena(arena);
+        LFH_block *block = LFH_arena_get_block(arena, -arena->next_free);
+        ssize_t extra = 0, limit;
+
+        if (arena == large_arena)
+        {
+            extra = ARENA_HEADER_SIZE;
+            limit = LARGE_ARENA_SIZE;
+            child = LFH_large_arena_from_block(block);
+            if (arena != child) child->parent = arena;
+        }
+        else limit = LFH_class_from_arena(large_arena)->size;
+
+        arena->next_free -= class->size + extra;
+        if (-arena->next_free > limit - class->size)
+            arena->next_free = 0;
+
+        arena->used_count++;
+        return block;
+    }
+}
+
+static inline int LFH_arena_is_empty(LFH_arena *arena)
+{
+    return arena->next_free == 0;
+}
+
+static inline int LFH_arena_is_used(LFH_arena *arena)
+{
+    return arena->used_count > 0;
+}
+
+static inline int LFH_class_is_block(LFH_heap *heap, LFH_class *class)
+{
+    return class >= heap->block_class && class < (heap->block_class + TOTAL_BLOCK_CLASS_COUNT);
+}
+
+static void LFH_class_initialize(LFH_heap *heap, LFH_class *class, size_t index)
+{
+    class->next = NULL;
+
+    if (LFH_class_is_block(heap, class))
+    {
+        if (index <= SMALL_CLASS_LAST)
+            class->size = min(SMALL_CLASS_MIN_SIZE + SMALL_CLASS_STEP * (index - SMALL_CLASS_FIRST), SMALL_CLASS_MAX_SIZE);
+        else
+            class->size = min(MEDIUM_CLASS_MIN_SIZE + MEDIUM_CLASS_STEP * (index - MEDIUM_CLASS_FIRST), MEDIUM_CLASS_MAX_SIZE);
+    }
+    else
+    {
+        class->size = min(LARGE_CLASS_MIN_SIZE + LARGE_CLASS_STEP * (index - LARGE_CLASS_FIRST), LARGE_CLASS_MAX_SIZE);
+    }
+}
+
+static inline LFH_arena *LFH_class_pop_arena(LFH_class *class)
+{
+    LFH_arena *arena = class->next;
+    if (!arena) return NULL;
+    class->next = arena->class_entry;
+    return arena;
+}
+
+static inline void LFH_class_remove_arena(LFH_class *class, LFH_arena *arena)
+{
+    LFH_arena **next = &class->next;
+    while (*next != arena) next = &(*next)->class_entry;
+    *next = arena->class_entry;
+}
+
+static inline LFH_arena *LFH_class_peek_arena(LFH_class *class)
+{
+    return class->next;
+}
+
+static inline void LFH_class_push_arena(LFH_class *class, LFH_arena *arena)
+{
+    arena->class_entry = class->next;
+    class->next = arena;
+}
+
+static inline LFH_class *LFH_heap_get_class(LFH_heap *heap, size_t size)
+{
+    if (size == 0)
+        return &heap->block_class[0];
+    else if (size <= SMALL_CLASS_MAX_SIZE)
+        return &heap->block_class[SMALL_CLASS_FIRST + (size + SMALL_CLASS_MASK - SMALL_CLASS_MIN_SIZE) / SMALL_CLASS_STEP];
+    else if (size <= MEDIUM_CLASS_MAX_SIZE)
+        return &heap->block_class[MEDIUM_CLASS_FIRST + (size + MEDIUM_CLASS_MASK - MEDIUM_CLASS_MIN_SIZE) / MEDIUM_CLASS_STEP];
+    else if (size <= LARGE_CLASS_MAX_SIZE)
+        return &heap->large_class[LARGE_CLASS_FIRST + (size + LARGE_CLASS_MASK - LARGE_CLASS_MIN_SIZE) / LARGE_CLASS_STEP];
+    else
+        return NULL;
+}
+
+static void LFH_arena_initialize(LFH_heap *heap, LFH_class *class, LFH_arena *arena, size_t huge_size)
+{
+    arena->class = class;
+    arena->next_free = -ARENA_HEADER_SIZE;
+
+    if (class == NULL)
+        arena->huge_size = huge_size;
+    else
+        arena->used_count = 0;
+}
+
+static LFH_arena *LFH_acquire_arena(LFH_heap *heap, LFH_class *class);
+static BOOLEAN LFH_release_arena(LFH_heap *heap, LFH_arena *arena);
+
+static inline LFH_block *LFH_allocate_block(LFH_heap *heap, LFH_class *class, LFH_arena *arena);
+static inline BOOLEAN LFH_deallocate_block(LFH_heap *heap, LFH_arena *arena, LFH_block *block);
+
+static inline BOOLEAN LFH_deallocate_deferred_blocks(LFH_heap *heap)
+{
+    LFH_slist *entry = LFH_slist_flush(&heap->list_defer);
+
+    while (entry)
+    {
+        LFH_block *block = LIST_ENTRY(entry, LFH_block, entry_defer);
+        entry = entry->next;
+
+        if (!LFH_deallocate_block(heap, LFH_arena_from_block(block), block))
+            return FALSE;
+    }
+
+    return TRUE;
+}
+
+static inline void LFH_deallocated_cached_arenas(LFH_heap *heap)
+{
+    if (!heap->cached_large_arena) return;
+    LFH_memory_deallocate(heap->cached_large_arena, LARGE_ARENA_SIZE);
+    heap->cached_large_arena = NULL;
+}
+
+static inline size_t LFH_huge_alloc_size(size_t size)
+{
+    return (ARENA_HEADER_SIZE + size + BLOCK_ARENA_MASK) & ~BLOCK_ARENA_MASK;
+}
+
+static inline LFH_arena *LFH_allocate_huge_arena(LFH_heap *heap, size_t size)
+{
+    LFH_arena *arena;
+    size_t alloc_size = LFH_huge_alloc_size(size);
+    if (alloc_size < size) return NULL;
+
+    if ((arena = LFH_memory_allocate(alloc_size)))
+        LFH_arena_initialize(heap, NULL, arena, size);
+
+    return arena;
+}
+
+static inline LFH_arena *LFH_allocate_large_arena(LFH_heap *heap, LFH_class *class)
+{
+    LFH_arena *arena;
+
+    if ((arena = heap->cached_large_arena) ||
+        (arena = LFH_memory_allocate(LARGE_ARENA_SIZE)))
+    {
+        heap->cached_large_arena = NULL;
+        LFH_arena_initialize(heap, class, arena, 0);
+        LFH_class_push_arena(class, arena);
+    }
+
+    return arena;
+}
+
+static inline LFH_arena *LFH_allocate_block_arena(LFH_heap *heap, LFH_class *large_class, LFH_class *block_class)
+{
+    LFH_arena *large_arena;
+    LFH_arena *arena = NULL;
+
+    if ((large_arena = LFH_acquire_arena(heap, large_class)))
+    {
+        arena = (LFH_arena *)LFH_allocate_block(heap, large_class, large_arena);
+        LFH_arena_initialize(heap, block_class, arena, 0);
+        LFH_class_push_arena(block_class, arena);
+    }
+
+    return arena;
+}
+
+static inline LFH_arena *LFH_acquire_arena(LFH_heap *heap, LFH_class *class)
+{
+    LFH_arena *arena;
+
+    if (!(arena = LFH_class_peek_arena(class)))
+    {
+        if (LFH_class_is_block(heap, class))
+            arena = LFH_allocate_block_arena(heap, &heap->large_class[0], class);
+        else
+            arena = LFH_allocate_large_arena(heap, class);
+    }
+
+    return arena;
+}
+
+static inline BOOLEAN LFH_release_arena(LFH_heap *heap, LFH_arena *arena)
+{
+    LFH_arena *large_arena = LFH_large_arena_from_block((LFH_block *)arena);
+    if (arena == large_arena && !heap->cached_large_arena)
+    {
+        heap->cached_large_arena = arena;
+        return TRUE;
+    }
+    else if (arena == large_arena)
+        return LFH_memory_deallocate(arena, LARGE_ARENA_SIZE);
+    else
+        return LFH_deallocate_block(heap, large_arena, (LFH_block *)arena);
+};
+
+static inline LFH_block *LFH_allocate_block(LFH_heap *heap, LFH_class *class, LFH_arena *arena)
+{
+    LFH_block *block = LFH_arena_pop_block(arena);
+    if (LFH_arena_is_empty(arena))
+        LFH_class_pop_arena(class);
+    return block;
+}
+
+static inline BOOLEAN LFH_deallocate_block(LFH_heap *heap, LFH_arena *arena, LFH_block *block)
+{
+    LFH_class *class = LFH_class_from_arena(arena);
+
+    arena = LFH_parent_from_arena(arena);
+    if (LFH_arena_is_empty(arena))
+        LFH_class_push_arena(class, arena);
+
+    LFH_arena_push_block(arena, block);
+    if (LFH_arena_is_used(arena))
+        return TRUE;
+
+    LFH_class_remove_arena(class, arena);
+    return LFH_release_arena(heap, arena);
+}
+
+static void LFH_heap_initialize(LFH_heap *heap)
+{
+    size_t i;
+
+    for (i = 0; i < TOTAL_LARGE_CLASS_COUNT; ++i)
+        LFH_class_initialize(heap, &heap->large_class[i], i);
+    for (i = 0; i < TOTAL_BLOCK_CLASS_COUNT; ++i)
+        LFH_class_initialize(heap, &heap->block_class[i], i);
+
+    heap->list_defer = NULL;
+    heap->cached_large_arena = NULL;
+}
+
+static SLIST_HEADER *LFH_orphan_list(void)
+{
+    static SLIST_HEADER *header;
+    SLIST_HEADER *ptr, *expected = NULL;
+    LFH_heap *tmp;
+
+    C_ASSERT(sizeof(LFH_heap) >= sizeof(SLIST_HEADER));
+
+    if ((ptr = __atomic_load_n(&header, __ATOMIC_RELAXED)))
+        return ptr;
+
+    if (!(ptr = LFH_memory_allocate(BLOCK_ARENA_SIZE)))
+        return NULL;
+
+    RtlInitializeSListHead(ptr);
+    for (tmp = (LFH_heap *)ptr + 1; tmp < (LFH_heap *)ptr + BLOCK_ARENA_SIZE / sizeof(*tmp); tmp++)
+    {
+        LFH_heap_initialize(tmp);
+        RtlInterlockedPushEntrySList(ptr, &tmp->entry_orphan);
+    }
+
+    if (__atomic_compare_exchange_n(&header, &expected, ptr, 0, __ATOMIC_RELEASE, __ATOMIC_ACQUIRE))
+        return ptr;
+
+    LFH_memory_deallocate(ptr, BLOCK_ARENA_SIZE);
+    return expected;
+}
+
+static void LFH_heap_finalize(LFH_heap *heap)
+{
+    LFH_arena *arena;
+
+    LFH_deallocate_deferred_blocks(heap);
+
+    for (size_t i = 0; i < TOTAL_BLOCK_CLASS_COUNT; ++i)
+    {
+        while ((arena = LFH_class_pop_arena(&heap->block_class[i])))
+        {
+            WARN("block arena %p still has used blocks\n", arena);
+            LFH_release_arena(heap, arena);
+        }
+    }
+
+    for (size_t i = 0; i < TOTAL_LARGE_CLASS_COUNT; ++i)
+    {
+        while ((arena = LFH_class_pop_arena(&heap->large_class[i])))
+        {
+            WARN("large arena %p still has used blocks\n", arena);
+            LFH_memory_deallocate(arena, LARGE_ARENA_SIZE);
+        }
+    }
+
+    LFH_deallocated_cached_arenas(heap);
+}
+
+static LFH_heap *LFH_heap_allocate(void)
+{
+    SLIST_HEADER *list_orphan = LFH_orphan_list();
+    LFH_heap *heap, *tmp;
+
+    heap = LFH_memory_allocate(BLOCK_ARENA_SIZE);
+    if (!heap)
+        return NULL;
+
+    for (tmp = heap + 1; tmp < heap + BLOCK_ARENA_SIZE / sizeof(*tmp); tmp++)
+    {
+        LFH_heap_initialize(tmp);
+        RtlInterlockedPushEntrySList(list_orphan, &tmp->entry_orphan);
+    }
+
+    LFH_heap_initialize(heap);
+    return heap;
+}
+
+static LFH_heap *LFH_create_thread_heap(void)
+{
+    SLIST_ENTRY *entry;
+    LFH_heap *heap;
+
+    if ((entry = RtlInterlockedPopEntrySList(LFH_orphan_list())))
+        heap = LIST_ENTRY(entry, LFH_heap, entry_orphan);
+    else
+        heap = LFH_heap_allocate();
+
+    return (NtCurrentTeb()->Reserved5[2] = heap);
+}
+
+static inline LFH_heap *LFH_thread_heap(BOOL create)
+{
+    LFH_heap *heap = (LFH_heap *)NtCurrentTeb()->Reserved5[2];
+    if (!heap && create) return LFH_create_thread_heap();
+    return heap;
+}
+
+static void LFH_dump_arena(LFH_heap *heap, LFH_class *class, LFH_arena *arena)
+{
+    LFH_arena *large_arena = LFH_large_arena_from_block((LFH_block *)arena);
+    LFH_arena *block_arena = LFH_block_arena_from_block((LFH_block *)arena);
+
+    if (arena == block_arena)
+        WARN("    block arena: %p-%p", arena, (void *)((UINT_PTR)large_arena + BLOCK_ARENA_SIZE - 1));
+    else if (arena == large_arena)
+        WARN("    large arena: %p-%p", arena, (void *)((UINT_PTR)large_arena + LARGE_ARENA_SIZE - 1));
+
+    WARN(" heap: %p class: %p parent: %p free: %Id used: %Id\n",
+          LFH_heap_from_arena(arena), LFH_class_from_arena(arena), LFH_parent_from_arena(arena), arena->next_free, arena->used_count);
+}
+
+static void LFH_dump_class(LFH_heap *heap, LFH_class *class)
+{
+    LFH_arena *arena = class->next;
+    if (!arena) return;
+
+    if (LFH_class_is_block(heap, class))
+        WARN("  block class: %p size: %Ix\n", class, class->size);
+    else
+        WARN("  large class: %p size: %Ix\n", class, class->size);
+
+    while (arena)
+    {
+        LFH_dump_arena(heap, class, arena);
+        arena = arena->class_entry;
+    }
+}
+
+static void LFH_dump_heap(LFH_heap *heap)
+{
+    size_t i;
+
+    WARN("heap: %p\n", heap);
+
+    for (i = 0; i < TOTAL_BLOCK_CLASS_COUNT; ++i)
+        LFH_dump_class(heap, &heap->block_class[i]);
+
+    for (i = 0; i < TOTAL_LARGE_CLASS_COUNT; ++i)
+        LFH_dump_class(heap, &heap->large_class[i]);
+}
+
+static BOOLEAN LFH_validate_arena(ULONG flags, const LFH_arena *arena);
+static BOOLEAN LFH_validate_heap(ULONG flags, const LFH_heap *heap);
+
+static inline BOOLEAN LFH_validate_block(ULONG flags, const LFH_block *block)
+{
+    const LFH_arena *arena = LFH_arena_from_block(block);
+    const LFH_arena *large_arena = LFH_large_arena_from_block(block);
+    const LFH_arena *block_arena = LFH_block_arena_from_block(block);
+    const LFH_arena *arena_arena = LFH_large_arena_from_block((LFH_block *)arena);
+    const char *err = NULL;
+
+    if (unlikely(flags & HEAP_VALIDATE))
+        return LFH_validate_arena(flags, arena);
+
+    if (unlikely(!arena))
+        err = "invalid arena";
+    else if (unlikely(arena != arena_arena && arena != (arena_arena + 1)))
+        err = "invalid arena alignment";
+     else if (likely(arena == block_arena))
+    {
+        if (unlikely((UINT_PTR)block < (UINT_PTR)block_arena + ARENA_HEADER_SIZE))
+            err = "invalid block alignment";
+        if (unlikely(((UINT_PTR)block & (sizeof(*block) - 1))))
+            err = "invalid block alignment";
+    }
+    else if (unlikely(arena != large_arena))
+        err = "large/huge arena mismatch";
+    else if (unlikely((UINT_PTR)block != (UINT_PTR)block_arena))
+        err = "invalid block for large/huge arena";
+
+    if (unlikely(err)) WARN("%08x %p: %s\n", flags, block, err);
+    return err == NULL;
+}
+
+static BOOLEAN LFH_validate_free_block(ULONG flags, const LFH_block *block)
+{
+    const char *err = NULL;
+
+    if (unlikely(!LFH_validate_block(flags, block)))
+        return FALSE;
+    if (unlikely(block->type != LFH_block_type_free))
+        err = "invalid free block type";
+
+    if (unlikely(err)) WARN("%08x %p: %s\n", flags, block, err);
+    return err == NULL;
+}
+
+static BOOLEAN LFH_validate_defer_block(ULONG flags, const LFH_block *block)
+{
+    const char *err = NULL;
+
+    if (unlikely(!LFH_validate_block(flags, block)))
+        return FALSE;
+    if (unlikely(block->type != LFH_block_type_free))
+        err = "invalid defer block type";
+    else if (unlikely(flags & HEAP_FREE_CHECKING_ENABLED))
+    {
+        const unsigned int *data = (const unsigned int *)LFH_ptr_from_block(block);
+        size_t class_size = LFH_block_get_class_size(block);
+        for (size_t i = 0; i < class_size / 4 - (data - (const unsigned int *)block) && !err; ++i)
+            if (unlikely(data[i] != 0xfeeefeee)) err = "invalid free filler";
+    }
+
+    if (unlikely(err)) WARN("%08x %p: %s\n", flags, block, err);
+    return err == NULL;
+}
+
+static inline BOOLEAN LFH_validate_used_block(ULONG flags, const LFH_block *block)
+{
+    const char *err = NULL;
+
+    if (unlikely(!LFH_validate_block(flags, block)))
+        return FALSE;
+    if (unlikely(block->type != LFH_block_type_used))
+        err = "invalid used block type";
+    else if (unlikely(flags & HEAP_TAIL_CHECKING_ENABLED))
+    {
+        const unsigned char *data = (const unsigned char *)LFH_ptr_from_block(block);
+        size_t alloc_size = LFH_block_get_alloc_size(block, flags);
+        size_t class_size = LFH_block_get_class_size(block);
+        for (size_t i = alloc_size; i < class_size - (data - (const unsigned char *)block) && !err; ++i)
+            if (data[i] != 0xab) err = "invalid tail filler";
+    }
+
+    if (unlikely(err)) WARN("%08x %p: %s\n", flags, block, err);
+    return err == NULL;
+}
+
+static BOOLEAN LFH_validate_arena_free_blocks(ULONG flags, const LFH_arena *arena)
+{
+    ssize_t offset = arena->next_free;
+    while (offset > 0)
+    {
+        LFH_block *block = LFH_arena_get_block(arena, offset);
+        if (!LFH_validate_free_block(flags, block))
+            return FALSE;
+        offset = block->next_free;
+    }
+
+    return TRUE;
+}
+
+static BOOLEAN LFH_validate_arena(ULONG flags, const LFH_arena *arena)
+{
+    const char *err = NULL;
+    const LFH_arena *parent;
+    const LFH_arena *block_arena = LFH_block_arena_from_block((LFH_block *)arena);
+    const LFH_arena *large_arena = LFH_large_arena_from_block((LFH_block *)arena);
+
+    if (unlikely(flags & HEAP_VALIDATE))
+        return LFH_validate_heap(flags, LFH_heap_from_arena(arena));
+
+    if (unlikely(arena != large_arena && arena != block_arena))
+        err = "invalid arena alignment";
+    else if (unlikely(arena == block_arena))
+    {
+        if (unlikely(!LFH_validate_block(flags, (LFH_block *)arena)))
+            err = "invalid block arena";
+        else if (unlikely(!LFH_validate_arena_free_blocks(flags, arena)))
+            err = "invalid block arena free list";
+    }
+    else if (unlikely(arena == large_arena && !LFH_class_from_arena(arena)))
+    {
+        if (unlikely(arena->huge_size <= LARGE_CLASS_MAX_SIZE))
+            err = "invalid huge arena size";
+    }
+    else if (unlikely(arena == large_arena && (parent = LFH_parent_from_arena(arena)) != arena))
+    {
+        if (unlikely(arena > parent || LFH_large_arena_from_block((LFH_block *)parent) != parent))
+            err = "invalid child arena parent";
+    }
+    else
+    {
+        if (unlikely(!LFH_validate_arena_free_blocks(flags, arena)))
+            err = "invalid large arena free list";
+    }
+
+    if (unlikely(err)) WARN("%08x %p: %s\n", flags, arena, err);
+    return err == NULL;
+}
+
+static BOOLEAN LFH_validate_class_arenas(ULONG flags, const LFH_class *class)
+{
+    LFH_arena *arena = class->next;
+    while (arena)
+    {
+        if (!LFH_validate_arena(flags, arena))
+            return FALSE;
+
+        arena = arena->class_entry;
+    }
+
+    return TRUE;
+}
+
+static BOOLEAN LFH_validate_heap_defer_blocks(ULONG flags, const LFH_heap *heap)
+{
+    const LFH_slist *entry = heap->list_defer;
+
+    while (entry)
+    {
+        const LFH_block *block = LIST_ENTRY(entry, LFH_block, entry_defer);
+        if (!LFH_validate_defer_block(flags, block))
+            return FALSE;
+        entry = entry->next;
+    }
+
+    return TRUE;
+}
+
+static BOOLEAN LFH_validate_heap(ULONG flags, const LFH_heap *heap)
+{
+    const char *err = NULL;
+    UINT i;
+
+    flags &= ~HEAP_VALIDATE;
+
+    if (heap != LFH_thread_heap(FALSE))
+        err = "unable to validate foreign heap";
+    else if (!LFH_validate_heap_defer_blocks(flags, heap))
+        err = "invalid heap defer blocks";
+    else
+    {
+        for (i = 0; err == NULL && i < TOTAL_BLOCK_CLASS_COUNT; ++i)
+        {
+            if (!LFH_validate_class_arenas(flags, &heap->block_class[i]))
+                return FALSE;
+        }
+
+        for (i = 0; err == NULL && i < TOTAL_LARGE_CLASS_COUNT; ++i)
+        {
+            if (!LFH_validate_class_arenas(flags, &heap->large_class[i]))
+                return FALSE;
+        }
+    }
+
+    if (unlikely(err)) WARN("%08x %p: %s\n", flags, heap, err);
+    return err == NULL;
+}
+
+static inline void LFH_block_initialize(LFH_block *block, ULONG flags, size_t old_size, size_t new_size, size_t class_size)
+{
+    char *ptr = (char *)LFH_ptr_from_block(block);
+
+    TRACE("block %p, flags %x, old_size %Ix, new_size %Ix, class_size %Ix, ptr %p\n", block, flags, old_size, new_size, class_size, ptr);
+
+    if ((flags & HEAP_ZERO_MEMORY) && new_size > old_size)
+        memset(ptr + old_size, 0, new_size - old_size);
+    else if ((flags & HEAP_FREE_CHECKING_ENABLED) && new_size > old_size && class_size < BLOCK_ARENA_SIZE)
+        memset(ptr + old_size, 0x55, new_size - old_size);
+
+    if ((flags & HEAP_TAIL_CHECKING_ENABLED))
+        memset(ptr + new_size, 0xab, class_size - new_size - (ptr - (char *)block));
+
+    block->type = LFH_block_type_used;
+    block->alloc_size = new_size;
+}
+
+static FORCEINLINE LFH_ptr *LFH_allocate(ULONG flags, size_t size)
+{
+    LFH_block *block = NULL;
+    LFH_class *class;
+    LFH_arena *arena;
+    LFH_heap *heap = LFH_thread_heap(TRUE);
+    size_t class_size = LFH_get_class_size(flags, size);
+
+    if (class_size == ~(size_t)0)
+        return NULL;
+
+    if (!LFH_deallocate_deferred_blocks(heap))
+        return NULL;
+
+    if ((class = LFH_heap_get_class(heap, class_size)))
+    {
+        arena = LFH_acquire_arena(heap, class);
+        if (arena) block = LFH_allocate_block(heap, class, arena);
+        if (block) LFH_block_initialize(block, flags, 0, size, LFH_block_get_class_size(block));
+    }
+    else
+    {
+        arena = LFH_allocate_huge_arena(heap, class_size);
+        if (arena) block = LFH_arena_get_block(arena, ARENA_HEADER_SIZE);
+        if (block) LFH_block_initialize(block, flags, 0, size, LFH_block_get_class_size(block));
+    }
+
+    LFH_deallocated_cached_arenas(heap);
+
+    if (!block) return NULL;
+    return LFH_ptr_from_block(block);
+}
+
+static FORCEINLINE BOOLEAN LFH_free(ULONG flags, LFH_ptr *ptr)
+{
+    LFH_block *block = LFH_block_from_ptr(ptr);
+    LFH_arena *arena = LFH_arena_from_block(block);
+    LFH_heap *heap = LFH_heap_from_arena(arena);
+
+    if (!LFH_class_from_arena(arena))
+        return LFH_memory_deallocate(arena, LFH_block_get_class_size(block));
+
+    if (flags & HEAP_FREE_CHECKING_ENABLED)
+    {
+        unsigned int *data = (unsigned int *)LFH_ptr_from_block(block);
+        size_t class_size = LFH_block_get_class_size(block);
+        for (size_t i = 0; i < class_size / 4 - (data - (const unsigned int *)block); ++i)
+            data[i] = 0xfeeefeee;
+    }
+
+    block->type = LFH_block_type_free;
+
+    if (heap == LFH_thread_heap(FALSE) && !(flags & HEAP_FREE_CHECKING_ENABLED))
+        LFH_deallocate_block(heap, LFH_arena_from_block(block), block);
+    else
+        LFH_slist_push(&heap->list_defer, &block->entry_defer);
+
+    return TRUE;
+}
+
+static FORCEINLINE LFH_ptr *LFH_reallocate(ULONG flags, LFH_ptr *old_ptr, size_t new_size)
+{
+    LFH_block *block = LFH_block_from_ptr(old_ptr);
+    LFH_arena *arena = LFH_arena_from_block(block);
+    LFH_heap *heap = LFH_heap_from_arena(arena);
+    size_t old_size = LFH_block_get_alloc_size(block, flags);
+    size_t old_class_size = LFH_block_get_class_size(block);
+    size_t new_class_size = LFH_get_class_size(flags, new_size);
+    LFH_class *new_class, *old_class = LFH_class_from_arena(arena);
+    LFH_ptr *new_ptr = NULL;
+
+    if (new_class_size == ~(size_t)0)
+        return NULL;
+
+    if (new_class_size <= old_class_size)
+        goto in_place;
+
+    if ((new_class = LFH_heap_get_class(heap, new_class_size)) && new_class == old_class)
+        goto in_place;
+
+    old_class_size = LFH_huge_alloc_size(old_class_size);
+    new_class_size = LFH_huge_alloc_size(new_class_size);
+    if (!new_class && !old_class && old_class_size == new_class_size)
+        goto in_place;
+
+    if (flags & HEAP_REALLOC_IN_PLACE_ONLY)
+        return NULL;
+
+    if (!(new_ptr = LFH_allocate(flags, new_size)))
+        return NULL;
+
+    memcpy(new_ptr, old_ptr, old_size);
+
+    if (LFH_free(flags, old_ptr))
+        return new_ptr;
+
+    LFH_free(flags, new_ptr);
+    return NULL;
+
+in_place:
+    LFH_block_initialize(block, flags, old_size, new_size, old_class_size);
+    return old_ptr;
+}
+
+static inline size_t LFH_get_allocated_size(ULONG flags, const LFH_ptr *ptr)
+{
+    const LFH_block *block = LFH_block_from_ptr(ptr);
+    return LFH_block_get_alloc_size(block, flags);
+}
+
+static inline BOOLEAN LFH_validate(ULONG flags, const LFH_ptr *ptr)
+{
+    const LFH_block *block = LFH_block_from_ptr(ptr);
+    const LFH_heap *heap;
+
+    /* clear HEAP_VALIDATE so we only validate block */
+    if (likely(ptr))
+        return LFH_validate_used_block(flags & ~HEAP_VALIDATE, block);
+
+    if (!(heap = LFH_thread_heap(FALSE)))
+        return TRUE;
+
+    return LFH_validate_heap(flags, heap);
+}
+
+static inline BOOLEAN LFH_try_validate_all(ULONG flags)
+{
+    if (likely(!(flags & HEAP_VALIDATE_ALL)))
+        return TRUE;
+
+    if (likely(LFH_validate(flags, NULL)))
+        return TRUE;
+
+    LFH_dump_heap(LFH_thread_heap(FALSE));
+    return FALSE;
+}
+
+NTSTATUS HEAP_lfh_allocate(HANDLE heap, ULONG flags, SIZE_T size, void **out)
+{
+    TRACE("heap %p, flags %08x, size %lx, out %p.\n", heap, flags, size, out);
+
+    if (unlikely(!LFH_try_validate_all(flags)))
+        return STATUS_INVALID_PARAMETER;
+
+    if (unlikely(!(*out = LFH_allocate(flags, size))))
+        return STATUS_NO_MEMORY;
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS HEAP_lfh_free(HANDLE heap, ULONG flags, void *ptr)
+{
+    TRACE("heap %p, flags %08x, ptr %p.\n", heap, flags, ptr);
+
+    if (unlikely(!LFH_try_validate_all(flags)))
+        return STATUS_INVALID_PARAMETER;
+
+    if (unlikely(!LFH_validate(flags, ptr)))
+        return STATUS_INVALID_PARAMETER;
+
+    if (unlikely(!LFH_free(flags, ptr)))
+        return STATUS_INVALID_PARAMETER;
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS HEAP_lfh_reallocate(HANDLE heap, ULONG flags, void *ptr, SIZE_T size, void **out)
+{
+    TRACE("heap %p, flags %08x, ptr %p, size %lx, out %p.\n", heap, flags, ptr, size, out);
+
+    if (unlikely(!LFH_try_validate_all(flags)))
+        return STATUS_INVALID_PARAMETER;
+
+    if (unlikely(!LFH_validate(flags, ptr)))
+        return STATUS_INVALID_PARAMETER;
+
+    if (unlikely(!(*out = LFH_reallocate(flags, ptr, size))))
+        return STATUS_NO_MEMORY;
+
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS HEAP_lfh_get_allocated_size(HANDLE heap, ULONG flags, const void *ptr, SIZE_T* out)
+{
+    TRACE("heap %p, flags %08x, ptr %p, out %p.\n", heap, flags, ptr, out);
+
+    if (unlikely(!LFH_try_validate_all(flags)))
+        return STATUS_INVALID_PARAMETER;
+
+    if (unlikely(!LFH_validate(flags, ptr)))
+        return STATUS_INVALID_PARAMETER;
+
+    *out = LFH_get_allocated_size(flags, ptr);
+    return STATUS_SUCCESS;
+}
+
+NTSTATUS HEAP_lfh_validate(HANDLE heap, ULONG flags, const void *ptr)
+{
+    TRACE("heap %p, flags %08x, ptr %p.\n", heap, flags, ptr);
+
+    if (unlikely(!LFH_try_validate_all(flags)))
+        return STATUS_INVALID_PARAMETER;
+
+    if (unlikely(!LFH_validate(flags, ptr)))
+        return STATUS_INVALID_PARAMETER;
+
+    return STATUS_SUCCESS;
+}
+
+void HEAP_lfh_notify_thread_destroy(BOOLEAN last)
+{
+    SLIST_HEADER *list_orphan = LFH_orphan_list();
+    SLIST_ENTRY *entry_orphan = NULL;
+    LFH_heap *heap;
+
+    if (last)
+    {
+        while ((entry_orphan || (entry_orphan = RtlInterlockedFlushSList(list_orphan))))
+        {
+            LFH_heap *orphan = LIST_ENTRY(entry_orphan, LFH_heap, entry_orphan);
+            entry_orphan = entry_orphan->Next;
+            LFH_heap_finalize(orphan);
+        }
+        LFH_memory_deallocate(list_orphan, BLOCK_ARENA_SIZE);
+    }
+    else if ((heap = LFH_thread_heap(FALSE)) && LFH_validate_heap(0, heap))
+        RtlInterlockedPushEntrySList(list_orphan, &heap->entry_orphan);
+}
+
+void HEAP_lfh_set_debug_flags(ULONG flags)
+{
+    LFH_heap *heap = LFH_thread_heap(FALSE);
+    if (!heap) return;
+
+    LFH_deallocate_deferred_blocks(heap);
+    LFH_deallocated_cached_arenas(heap);
+}
\ No newline at end of file
diff --git a/dlls/ntdll/loader.c b/dlls/ntdll/loader.c
index d11f3f0f79d..711da19e29f 100644
--- a/dlls/ntdll/loader.c
+++ b/dlls/ntdll/loader.c
@@ -3536,6 +3536,7 @@ void WINAPI RtlExitUserProcess( DWORD status )
     RtlAcquirePebLock();
     NtTerminateProcess( 0, status );
     LdrShutdownProcess();
+    HEAP_notify_thread_destroy(TRUE);
     for (;;) NtTerminateProcess( GetCurrentProcess(), status );
 }
 
@@ -3973,6 +3974,7 @@ void WINAPI LdrInitializeThunk( CONTEXT *context, ULONG_PTR unknown2, ULONG_PTR
         ANSI_STRING func_name;
         WINE_MODREF *kernel32;
         PEB *peb = NtCurrentTeb()->Peb;
+        DWORD hci = 2;
 
         peb->LdrData            = &ldr;
         peb->FastPebLock        = &peb_lock;
@@ -3996,6 +3998,7 @@ void WINAPI LdrInitializeThunk( CONTEXT *context, ULONG_PTR unknown2, ULONG_PTR
         wm->ldr.LoadCount = -1;
 
         build_ntdll_module();
+        RtlSetHeapInformation( GetProcessHeap(), HeapCompatibilityInformation, &hci, sizeof(hci) );
 
         if (NtCurrentTeb()->WowTebOffset) init_wow64( context );
 
diff --git a/dlls/ntdll/ntdll_misc.h b/dlls/ntdll/ntdll_misc.h
index d7c5ade5bc1..0f1c2915e86 100644
--- a/dlls/ntdll/ntdll_misc.h
+++ b/dlls/ntdll/ntdll_misc.h
@@ -110,6 +110,31 @@ static inline TEB64 *NtCurrentTeb64(void) { return NULL; }
 static inline TEB64 *NtCurrentTeb64(void) { return (TEB64 *)NtCurrentTeb()->GdiBatchCount; }
 #endif
 
+#define HEAP_STD 0
+#define HEAP_LAL 1
+#define HEAP_LFH 2
+
+/* some undocumented flags (names are made up) */
+#define HEAP_PAGE_ALLOCS      0x01000000
+#define HEAP_VALIDATE         0x10000000
+#define HEAP_VALIDATE_ALL     0x20000000
+#define HEAP_VALIDATE_PARAMS  0x40000000
+
+NTSTATUS HEAP_std_allocate( HANDLE heap, ULONG flags, SIZE_T size, void **out );
+NTSTATUS HEAP_std_free( HANDLE heap, ULONG flags, void *ptr );
+NTSTATUS HEAP_std_reallocate( HANDLE heap, ULONG flags, void *ptr, SIZE_T size, void **out );
+NTSTATUS HEAP_std_get_allocated_size( HANDLE heap, ULONG flags, const void *ptr, SIZE_T *out );
+
+NTSTATUS HEAP_lfh_allocate( HANDLE std_heap, ULONG flags, SIZE_T size, void **out );
+NTSTATUS HEAP_lfh_free( HANDLE std_heap, ULONG flags, void *ptr );
+NTSTATUS HEAP_lfh_reallocate( HANDLE std_heap, ULONG flags, void *ptr, SIZE_T size, void **out );
+NTSTATUS HEAP_lfh_get_allocated_size( HANDLE std_heap, ULONG flags, const void *ptr, SIZE_T *out );
+NTSTATUS HEAP_lfh_validate( HANDLE std_heap, ULONG flags, const void *ptr );
+
+void HEAP_notify_thread_destroy( BOOLEAN last );
+void HEAP_lfh_notify_thread_destroy( BOOLEAN last );
+void HEAP_lfh_set_debug_flags( ULONG flags );
+
 #define HASH_STRING_ALGORITHM_DEFAULT  0
 #define HASH_STRING_ALGORITHM_X65599   1
 #define HASH_STRING_ALGORITHM_INVALID  0xffffffff
diff --git a/dlls/ntdll/string.c b/dlls/ntdll/string.c
index 0fa83821d21..78f37a8ac81 100644
--- a/dlls/ntdll/string.c
+++ b/dlls/ntdll/string.c
@@ -24,6 +24,7 @@
 #include <stdarg.h>
 #include <stdlib.h>
 #include <stdio.h>
+#include <stdint.h>
 #include <string.h>
 #include <stdint.h>
 
@@ -93,6 +94,128 @@ int __cdecl memcmp( const void *ptr1, const void *ptr2, size_t n )
     return 0;
 }
 
+static FORCEINLINE void memmove_c_unaligned_32( char *d, const char *s, size_t n )
+{
+    uint64_t tmp0, tmp1, tmp2, tmpn;
+
+    if (n >= 24)
+    {
+        tmp0 = *(uint64_t *)s;
+        tmp1 = *(uint64_t *)(s + 8);
+        tmp2 = *(uint64_t *)(s + 16);
+        tmpn = *(uint64_t *)(s + n - 8);
+        *(uint64_t *)d = tmp0;
+        *(uint64_t *)(d + 8) = tmp1;
+        *(uint64_t *)(d + 16) = tmp2;
+        *(uint64_t *)(d + n - 8) = tmpn;
+    }
+    else if (n >= 16)
+    {
+        tmp0 = *(uint64_t *)s;
+        tmp1 = *(uint64_t *)(s + 8);
+        tmpn = *(uint64_t *)(s + n - 8);
+        *(uint64_t *)d = tmp0;
+        *(uint64_t *)(d + 8) = tmp1;
+        *(uint64_t *)(d + n - 8) = tmpn;
+    }
+    else if (n >= 8)
+    {
+        tmp0 = *(uint64_t *)s;
+        tmpn = *(uint64_t *)(s + n - 8);
+        *(uint64_t *)d = tmp0;
+        *(uint64_t *)(d + n - 8) = tmpn;
+    }
+    else if (n >= 4)
+    {
+        tmp0 = *(uint32_t *)s;
+        tmpn = *(uint32_t *)(s + n - 4);
+        *(uint32_t *)d = tmp0;
+        *(uint32_t *)(d + n - 4) = tmpn;
+    }
+    else if (n >= 2)
+    {
+        tmp0 = *(uint16_t *)s;
+        tmpn = *(uint16_t *)(s + n - 2);
+        *(uint16_t *)d = tmp0;
+        *(uint16_t *)(d + n - 2) = tmpn;
+    }
+    else if (n >= 1)
+    {
+        *(uint8_t *)d = *(uint8_t *)s;
+    }
+}
+
+
+static FORCEINLINE void *memmove_c( char *d, const char *s, size_t n )
+{
+    if (n <= 32) memmove_c_unaligned_32( d, s, n );
+    else if (d <= s)
+    {
+        uint64_t tmp0, tmp1, tmp2;
+        size_t k = 0;
+        while (n >= 48)
+        {
+            tmp0 = *(uint64_t *)(s +  0);
+            tmp1 = *(uint64_t *)(s +  8);
+            tmp2 = *(uint64_t *)(s + 16);
+            *(uint64_t*)(d +  0) = tmp0;
+            *(uint64_t*)(d +  8) = tmp1;
+            *(uint64_t*)(d + 16) = tmp2;
+            tmp0 = *(uint64_t *)(s + 24);
+            tmp1 = *(uint64_t *)(s + 32);
+            tmp2 = *(uint64_t *)(s + 40);
+            *(uint64_t*)(d + 24) = tmp0;
+            *(uint64_t*)(d + 32) = tmp1;
+            *(uint64_t*)(d + 40) = tmp2;
+            d += 48; s += 48; n -= 48; k += 48;
+        }
+        while (n >= 24)
+        {
+            tmp0 = *(uint64_t *)(s +  0);
+            tmp1 = *(uint64_t *)(s +  8);
+            tmp2 = *(uint64_t *)(s + 16);
+            *(uint64_t*)(d +  0) = tmp0;
+            *(uint64_t*)(d +  8) = tmp1;
+            *(uint64_t*)(d + 16) = tmp2;
+            d += 24; s += 24; n -= 24; k += 24;
+        }
+        memmove_c_unaligned_32( d, s, n );
+        return d - k;
+    }
+    else
+    {
+        uint64_t tmp0, tmp1, tmp2;
+        size_t k = n;
+        while (k >= 48)
+        {
+            tmp0 = *(uint64_t *)(s + k -  8);
+            tmp1 = *(uint64_t *)(s + k - 16);
+            tmp2 = *(uint64_t *)(s + k - 24);
+            *(uint64_t*)(d + k -  8) = tmp0;
+            *(uint64_t*)(d + k - 16) = tmp1;
+            *(uint64_t*)(d + k - 24) = tmp2;
+            tmp0 = *(uint64_t *)(s + k - 32);
+            tmp1 = *(uint64_t *)(s + k - 40);
+            tmp2 = *(uint64_t *)(s + k - 48);
+            *(uint64_t*)(d + k - 32) = tmp0;
+            *(uint64_t*)(d + k - 40) = tmp1;
+            *(uint64_t*)(d + k - 48) = tmp2;
+            k -= 48;
+        }
+        while (k >= 24)
+        {
+            tmp0 = *(uint64_t *)(s + k -  8);
+            tmp1 = *(uint64_t *)(s + k - 16);
+            tmp2 = *(uint64_t *)(s + k - 24);
+            *(uint64_t*)(d + k -  8) = tmp0;
+            *(uint64_t*)(d + k - 16) = tmp1;
+            *(uint64_t*)(d + k - 24) = tmp2;
+            k -= 24;
+        }
+        memmove_c_unaligned_32( d, s, k );
+    }
+    return d;
+}
 
 /*********************************************************************
  *                  memcpy   (NTDLL.@)
@@ -102,20 +225,7 @@ int __cdecl memcmp( const void *ptr1, const void *ptr2, size_t n )
  */
 void * __cdecl memcpy( void *dst, const void *src, size_t n )
 {
-    volatile unsigned char *d = dst;  /* avoid gcc optimizations */
-    const unsigned char *s = src;
-
-    if ((size_t)dst - (size_t)src >= n)
-    {
-        while (n--) *d++ = *s++;
-    }
-    else
-    {
-        d += n - 1;
-        s += n - 1;
-        while (n--) *d-- = *s--;
-    }
-    return dst;
+    return memmove_c( dst, src, n );
 }
 
 
@@ -124,23 +234,45 @@ void * __cdecl memcpy( void *dst, const void *src, size_t n )
  */
 void * __cdecl memmove( void *dst, const void *src, size_t n )
 {
-    volatile unsigned char *d = dst;  /* avoid gcc optimizations */
-    const unsigned char *s = src;
+    return memmove_c( dst, src, n );
+}
 
-    if ((size_t)dst - (size_t)src >= n)
+static FORCEINLINE void memset_c_unaligned_32( char *d, uint64_t v, size_t n )
+{
+    if (n >= 24)
+    {
+        *(uint64_t *)d = v;
+        *(uint64_t *)(d + 8) = v;
+        *(uint64_t *)(d + 16) = v;
+        *(uint64_t *)(d + n - 8) = v;
+    }
+    else if (n >= 16)
     {
-        while (n--) *d++ = *s++;
+        *(uint64_t *)d = v;
+        *(uint64_t *)(d + 8) = v;
+        *(uint64_t *)(d + n - 8) = v;
     }
-    else
+    else if (n >= 8)
     {
-        d += n - 1;
-        s += n - 1;
-        while (n--) *d-- = *s--;
+        *(uint64_t *)d = v;
+        *(uint64_t *)(d + n - 8) = v;
+    }
+    else if (n >= 4)
+    {
+        *(uint32_t *)d = v;
+        *(uint32_t *)(d + n - 4) = v;
+    }
+    else if (n >= 2)
+    {
+        *(uint16_t *)d = v;
+        *(uint16_t *)(d + n - 2) = v;
+    }
+    else if (n >= 1)
+    {
+        *(uint8_t *)d = v;
     }
-    return dst;
 }
 
-
 static inline void memset_aligned_32( unsigned char *d, uint64_t v, size_t n )
 {
     unsigned char *end = d + n;
@@ -157,56 +289,38 @@ static inline void memset_aligned_32( unsigned char *d, uint64_t v, size_t n )
 /*********************************************************************
  *                  memset   (NTDLL.@)
  */
-void *__cdecl memset( void *dst, int c, size_t n )
+void *__cdecl memset(void *dst, int c, size_t n)
 {
-    typedef uint64_t DECLSPEC_ALIGN(1) unaligned_ui64;
-    typedef uint32_t DECLSPEC_ALIGN(1) unaligned_ui32;
-    typedef uint16_t DECLSPEC_ALIGN(1) unaligned_ui16;
+    uint16_t tmp16 = ((uint16_t)c << 8) | c;
+    uint32_t tmp32 = ((uint32_t)tmp16 << 16) | tmp16;
+    uint64_t v = ((uint64_t)tmp32 << 32) | tmp32;
 
-    uint64_t v = 0x101010101010101ull * (unsigned char)c;
-    unsigned char *d = (unsigned char *)dst;
-    size_t a = 0x20 - ((uintptr_t)d & 0x1f);
-
-    if (n >= 16)
-    {
-        *(unaligned_ui64 *)(d + 0) = v;
-        *(unaligned_ui64 *)(d + 8) = v;
-        *(unaligned_ui64 *)(d + n - 16) = v;
-        *(unaligned_ui64 *)(d + n - 8) = v;
-        if (n <= 32) return dst;
-        *(unaligned_ui64 *)(d + 16) = v;
-        *(unaligned_ui64 *)(d + 24) = v;
-        *(unaligned_ui64 *)(d + n - 32) = v;
-        *(unaligned_ui64 *)(d + n - 24) = v;
-        if (n <= 64) return dst;
-
-        n = (n - a) & ~0x1f;
-        memset_aligned_32( d + a, v, n );
-        return dst;
-    }
-    if (n >= 8)
+    if (n <= 32)
     {
-        *(unaligned_ui64 *)d = v;
-        *(unaligned_ui64 *)(d + n - 8) = v;
+        memset_c_unaligned_32( dst, v, n );
         return dst;
     }
-    if (n >= 4)
-    {
-        *(unaligned_ui32 *)d = v;
-        *(unaligned_ui32 *)(d + n - 4) = v;
-        return dst;
-    }
-    if (n >= 2)
+
+    while (n >= 48)
     {
-        *(unaligned_ui16 *)d = v;
-        *(unaligned_ui16 *)(d + n - 2) = v;
-        return dst;
+        *(uint64_t*)((char *)dst + n -  8) = v;
+        *(uint64_t*)((char *)dst + n - 16) = v;
+        *(uint64_t*)((char *)dst + n - 24) = v;
+        *(uint64_t*)((char *)dst + n - 32) = v;
+        *(uint64_t*)((char *)dst + n - 40) = v;
+        *(uint64_t*)((char *)dst + n - 48) = v;
+        n -= 48;
     }
-    if (n >= 1)
+
+    while (n >= 24)
     {
-        *(uint8_t *)d = v;
-        return dst;
+        *(uint64_t*)((char *)dst + n -  8) = v;
+        *(uint64_t*)((char *)dst + n - 16) = v;
+        *(uint64_t*)((char *)dst + n - 24) = v;
+        n -= 24;
     }
+
+    memset_c_unaligned_32( dst, v, n );
     return dst;
 }
 
diff --git a/dlls/ntdll/thread.c b/dlls/ntdll/thread.c
index 37dc7c8ab37..fc9055ca09f 100644
--- a/dlls/ntdll/thread.c
+++ b/dlls/ntdll/thread.c
@@ -188,6 +188,7 @@ void WINAPI RtlExitUserThread( ULONG status )
     NtQueryInformationThread( GetCurrentThread(), ThreadAmILastThread, &last, sizeof(last), NULL );
     if (last) RtlExitUserProcess( status );
     LdrShutdownThread();
+    HEAP_notify_thread_destroy(FALSE);
     for (;;) NtTerminateThread( GetCurrentThread(), status );
 }
 
diff --git a/dlls/ntdll/unix/unix_private.h b/dlls/ntdll/unix/unix_private.h
index d9ce8300fa9..48d4e64e845 100644
--- a/dlls/ntdll/unix/unix_private.h
+++ b/dlls/ntdll/unix/unix_private.h
@@ -61,6 +61,7 @@ struct ntdll_thread_data
     PRTL_THREAD_START_ROUTINE start;  /* thread entry point */
     void              *param;         /* thread entry point parameter */
     void              *jmp_buf;       /* setjmp buffer for exception handling */
+    void              *heap;          /* thread local heap data */
 };
 
 C_ASSERT( sizeof(struct ntdll_thread_data) <= sizeof(((TEB *)0)->GdiTebBatch) );
diff --git a/include/winnt.h b/include/winnt.h
index c80efee077d..b3bbb8a58b8 100644
--- a/include/winnt.h
+++ b/include/winnt.h
@@ -934,7 +934,8 @@ NTSYSAPI WORD         WINAPI RtlQueryDepthSList(PSLIST_HEADER);
 #define HEAP_SHARED                     0x04000000
 
 typedef enum _HEAP_INFORMATION_CLASS {
-    HeapCompatibilityInformation,
+    HeapCompatibilityInformation = 0,
+    HeapEnableTerminationOnCorruption = 1,
 } HEAP_INFORMATION_CLASS;
 
 /* Processor feature flags.  */
-- 
2.33.1

